<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>deepshare_python基础3</title>
      <link href="/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%803/"/>
      <url>/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%803/</url>
      
        <content type="html"><![CDATA[<h1 id="第一部分-数字类型"><a href="#第一部分-数字类型" class="headerlink" title="第一部分 数字类型"></a>第一部分 数字类型</h1><h2 id="1-1-数字类型的组成"><a href="#1-1-数字类型的组成" class="headerlink" title="1.1 数字类型的组成"></a>1.1 数字类型的组成</h2><h3 id="1-1-1-整数——不同进制的转换"><a href="#1-1-1-整数——不同进制的转换" class="headerlink" title="1.1.1 整数——不同进制的转换"></a>1.1.1 整数——不同进制的转换</h3><ul><li>默认输入十进制</li><li>二进制0b、八进制0o、十六进制0x</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">16</span> == <span class="number">0b10000</span> == <span class="number">0o20</span> == <span class="number">0x10</span></span><br></pre></td></tr></table></figure><pre><code>True</code></pre><ul><li>十进制与其他进制的转换</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = bin(<span class="number">16</span>) <span class="comment"># 转二进制</span></span><br><span class="line">b = oct(<span class="number">16</span>) <span class="comment"># 转八进制</span></span><br><span class="line">c = hex(<span class="number">16</span>) <span class="comment"># 转十六进制</span></span><br><span class="line">print(a, b, c)</span><br></pre></td></tr></table></figure><pre><code>0b10000 0o20 0x10</code></pre><p>==注意：上述转换后的结果为字符串类型==</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a == b == c</span><br><span class="line">print(<span class="string">"-------分割线-------"</span>)</span><br><span class="line">print(type(a), type(b), type(c))</span><br><span class="line">print(<span class="string">"-------分割线-------"</span>)</span><br><span class="line">print(eval(a) == eval(b) == eval(c))</span><br><span class="line">print(type(a), type(eval(a)))</span><br></pre></td></tr></table></figure><pre><code>-------分割线-------&lt;class &#39;str&#39;&gt; &lt;class &#39;str&#39;&gt; &lt;class &#39;str&#39;&gt;-------分割线-------True&lt;class &#39;str&#39;&gt; &lt;class &#39;int&#39;&gt;</code></pre><ul><li>其他进制转十进制</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d = int(a, <span class="number">2</span>) <span class="comment"># 二进制转十进制</span></span><br><span class="line">e = int(b, <span class="number">8</span>) <span class="comment"># 八进制转十进制</span></span><br><span class="line">f = int(c, <span class="number">16</span>) <span class="comment"># 十六进制转十进制</span></span><br><span class="line">print(d, e, f)</span><br></pre></td></tr></table></figure><pre><code>16 16 16</code></pre><h3 id="1-1-2-浮点数——不确定性"><a href="#1-1-2-浮点数——不确定性" class="headerlink" title="1.1.2 浮点数——不确定性"></a>1.1.2 浮点数——不确定性</h3><ul><li>不确定小数问题</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0.1</span>+<span class="number">0.2</span>) == <span class="number">0.3</span></span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.1</span>+<span class="number">0.2</span></span><br></pre></td></tr></table></figure><pre><code>0.30000000000000004</code></pre><p><strong>计算机采用二进制小数来表示浮点数的小数部分</strong></p><ul><li><p>但部分小数不能用二进制小数完全表示</p></li><li><p>四舍五入获得精确解</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">3</span> * <span class="number">0.1</span></span><br><span class="line">print(a)</span><br><span class="line">print(<span class="string">"-----------分割线-----------"</span>)</span><br><span class="line">b = round(a, <span class="number">1</span>) <span class="comment"># 1表示保留的小数位数</span></span><br><span class="line">print(b, b == <span class="number">0.3</span>)</span><br></pre></td></tr></table></figure><pre><code>0.30000000000000004-----------分割线-----------0.3 True</code></pre><h3 id="1-1-3-复数——a-bj"><a href="#1-1-3-复数——a-bj" class="headerlink" title="1.1.3 复数——a+bj"></a>1.1.3 复数——a+bj</h3><ul><li>大写J或小写j均可</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="number">3</span>+<span class="number">4j</span>))</span><br><span class="line">print(type(<span class="number">2</span>+<span class="number">5J</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;complex&#39;&gt;&lt;class &#39;complex&#39;&gt;</code></pre><ul><li>虚部系数为1时，需要显式写出</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2+j 会报错</span></span><br><span class="line"><span class="number">2</span> + <span class="number">1j</span></span><br></pre></td></tr></table></figure><pre><code>(2+1j)</code></pre><h2 id="1-2-数字运算操作符（a操作符b）"><a href="#1-2-数字运算操作符（a操作符b）" class="headerlink" title="1.2 数字运算操作符（a操作符b）"></a>1.2 数字运算操作符（a操作符b）</h2><ul><li>加减乘除 <code>+ - * /</code></li><li>乘方运算<code>**</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span>**<span class="number">3</span></span><br></pre></td></tr></table></figure><pre><code>8</code></pre><ul><li>整数商<code>//</code>和取余数<code>%</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">13</span>//<span class="number">5</span>)</span><br><span class="line">print(<span class="number">13</span>%<span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>23</code></pre><p><strong>几点说明</strong></p><ul><li>整数与浮点数运算结果是浮点数</li><li>除法运算的结果是浮点数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">8</span>/<span class="number">4</span></span><br></pre></td></tr></table></figure><pre><code>2.0</code></pre><h2 id="1-3-数字运算操作函数function-x-…"><a href="#1-3-数字运算操作函数function-x-…" class="headerlink" title="1.3 数字运算操作函数function(x,…)"></a>1.3 数字运算操作函数function(x,…)</h2><ul><li>求绝对值<code>abs()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abs(<span class="number">-5</span>)</span><br></pre></td></tr></table></figure><pre><code>5</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abs(<span class="number">3</span>+<span class="number">4j</span>)</span><br></pre></td></tr></table></figure><pre><code>5.0</code></pre><ul><li>幂次方<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pow(x,n,t) <span class="comment"># x^n % t</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pow(<span class="number">2</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pow(<span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><pre><code>2</code></pre><ul><li>四舍五入<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">round(x,n) <span class="comment"># 参数n表示保留n位小数</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1.618</span></span><br><span class="line">print(round(a)) <span class="comment"># 默认四舍五入为整数</span></span><br><span class="line">print(round(a, <span class="number">2</span>))</span><br><span class="line">print(round(a, <span class="number">5</span>)) <span class="comment"># 位数不足，不会补齐</span></span><br></pre></td></tr></table></figure><pre><code>21.621.618</code></pre><ul><li>整数商和取余<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">divmod(x,y)</span><br></pre></td></tr></table></figure></li><li>等价于返回二元元组(x//y, x%y)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">divmod(<span class="number">13</span>, <span class="number">5</span>) <span class="comment"># 较(x//y, x%y)更快，只执行了一次x/y</span></span><br></pre></td></tr></table></figure><pre><code>(2, 3)</code></pre><ul><li>序列最大/最小值max()，min()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">print(<span class="string">"max:"</span>, max(a))</span><br><span class="line">print(<span class="string">"min:"</span>, min(a))</span><br></pre></td></tr></table></figure><pre><code>max: 9min: 2</code></pre><ul><li>求和sum(x)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>15</code></pre><ul><li>借助科学计算库math\scipy\numpy</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line">print(math.exp(<span class="number">1</span>)) <span class="comment"># 指数运算e^x</span></span><br><span class="line">print(math.log2(<span class="number">2</span>)) <span class="comment"># 对数运算</span></span><br><span class="line">print(math.sqrt(<span class="number">4</span>)) <span class="comment"># 开平方运算</span></span><br></pre></td></tr></table></figure><pre><code>2.7182818284590451.02.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">print(np.mean(a)) <span class="comment"># 求均值</span></span><br><span class="line">print(np.median(a)) <span class="comment"># 求中位数</span></span><br><span class="line">print(np.std(a)) <span class="comment"># 求标准差</span></span><br></pre></td></tr></table></figure><pre><code>3.03.01.4142135623730951</code></pre><h1 id="第二部分-字符串类型"><a href="#第二部分-字符串类型" class="headerlink" title="第二部分 字符串类型"></a>第二部分 字符串类型</h1><h2 id="2-1-字符串的表达"><a href="#2-1-字符串的表达" class="headerlink" title="2.1 字符串的表达"></a>2.1 字符串的表达</h2><ul><li>用<code>&quot;&quot;</code>或<code>&#39;&#39;</code>括起来表示字符串</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Python"</span>)</span><br><span class="line">print(<span class="string">'Python'</span>)</span><br></pre></td></tr></table></figure><pre><code>PythonPython</code></pre><ul><li>字符串中有双引号或单引号的情况</li></ul><p><strong>双中有单</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"I'm 18 years old"</span>)</span><br></pre></td></tr></table></figure><pre><code>I&#39;m 18 years old</code></pre><p><strong>单中有双</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'"Python" is good'</span>)</span><br></pre></td></tr></table></figure><pre><code>&quot;Python&quot; is good</code></pre><p><strong>双中有双，单中有单——用转义符\</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"\"Python\" is good"</span>)</span><br></pre></td></tr></table></figure><pre><code>&quot;Python&quot; is good</code></pre><p><strong>转义符可以用来换行输入</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"py\</span></span><br><span class="line"><span class="string">thon"</span></span><br><span class="line">print(s)</span><br></pre></td></tr></table></figure><pre><code>python</code></pre><h2 id="2-2-字符串的性质"><a href="#2-2-字符串的性质" class="headerlink" title="2.2 字符串的性质"></a>2.2 字符串的性质</h2><h3 id="2-2-1-字符串的索引"><a href="#2-2-1-字符串的索引" class="headerlink" title="2.2.1 字符串的索引"></a>2.2.1 字符串的索引</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"My name is Peppa Pig"</span></span><br></pre></td></tr></table></figure><p><strong>变量名[位置编号]</strong></p><ul><li>正向索引——从零开始递增</li><li>位置编号不能超过字符串的长度</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(s[<span class="number">0</span>])</span><br><span class="line">print(s[<span class="number">2</span>])</span><br><span class="line">print(s[<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>Mm</code></pre><ul><li>反向索引——从-1开始递减</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(s[<span class="number">-1</span>])</span><br><span class="line">print(s[<span class="number">-3</span>])</span><br><span class="line">print(s[<span class="number">-5</span>])</span><br></pre></td></tr></table></figure><pre><code>gPa</code></pre><p><strong>索引只能获得一个字符，如何获得多个字符？</strong></p><h3 id="2-2-2-字符串的切片"><a href="#2-2-2-字符串的切片" class="headerlink" title="2.2.2 字符串的切片"></a>2.2.2 字符串的切片</h3><p><strong>变量名[start:end:间隔]</strong></p><ul><li>切片间隔默认为1，可省略</li><li>切片范围不包含end</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"Python"</span></span><br><span class="line">print(s[<span class="number">0</span>:<span class="number">3</span>:<span class="number">1</span>])</span><br><span class="line">print(s[<span class="number">0</span>:<span class="number">3</span>:<span class="number">2</span>])</span><br><span class="line">print(s[<span class="number">0</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>PytPtPyt</code></pre><ul><li>起始位置是0可以省略</li><li>结束位置省略，代表取到最后一个字符</li><li>可以使用反向索引</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"Python"</span></span><br><span class="line">print(s[<span class="number">0</span>:<span class="number">6</span>])</span><br><span class="line">print(s[:<span class="number">6</span>])</span><br><span class="line">print(s[:])</span><br><span class="line">print(s[<span class="number">-6</span>:])</span><br></pre></td></tr></table></figure><pre><code>PythonPythonPythonPython</code></pre><p><strong>反向切片<code>str[::-1]</code></strong></p><ul><li>起始位置是-1可以省略</li><li>结束位置省略，代表取到第一个字符</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"123456789"</span></span><br><span class="line">print(s[<span class="number">-3</span>:<span class="number">-10</span>:<span class="number">-1</span>])</span><br><span class="line">print(s)</span><br><span class="line">print(s[<span class="number">-1</span>:<span class="number">-10</span>])</span><br><span class="line">print(s[:<span class="number">-10</span>:<span class="number">-1</span>])</span><br><span class="line">print(s[::<span class="number">-1</span>])</span><br><span class="line">print(s[<span class="number">0</span>:<span class="number">5</span>:<span class="number">-1</span>]) <span class="comment"># 注：start+interval是往end方向才有正常输出</span></span><br><span class="line">print(<span class="string">"-------------"</span>)</span><br></pre></td></tr></table></figure><pre><code>7654321123456789987654321987654321-------------</code></pre><h2 id="2-3-字符串操作符"><a href="#2-3-字符串操作符" class="headerlink" title="2.3 字符串操作符"></a>2.3 字符串操作符</h2><h3 id="2-3-1-字符串的拼接"><a href="#2-3-1-字符串的拼接" class="headerlink" title="2.3.1 字符串的拼接"></a>2.3.1 字符串的拼接</h3><ul><li>字符串1+字符串2</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">"I love "</span></span><br><span class="line">b = <span class="string">"my girlfriend "</span></span><br><span class="line">a + b</span><br></pre></td></tr></table></figure><pre><code>&#39;I love my girlfriend &#39;</code></pre><h3 id="2-3-2-字符串的成倍复制"><a href="#2-3-2-字符串的成倍复制" class="headerlink" title="2.3.2 字符串的成倍复制"></a>2.3.2 字符串的成倍复制</h3><ul><li><code>字符串*n, n*字符串</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c = a + b</span><br><span class="line">print(c * <span class="number">3</span>)</span><br><span class="line">print(<span class="number">3</span> * c)</span><br></pre></td></tr></table></figure><pre><code>I love my girlfriend I love my girlfriend I love my girlfriend I love my girlfriend I love my girlfriend I love my girlfriend </code></pre><h3 id="2-3-3-成员运算"><a href="#2-3-3-成员运算" class="headerlink" title="2.3.3 成员运算"></a>2.3.3 成员运算</h3><ul><li>子集in全集，判断子集是否在全集中（任何一个连续的切片都是原字符串的子集）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">folk_singers = <span class="string">"Peter, Paul and Mary"</span></span><br><span class="line"><span class="string">"Peter"</span> <span class="keyword">in</span> folk_singers</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><ul><li>遍历字符串字符<code>for 字符 in 字符串</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> <span class="string">"Python"</span>:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure><pre><code>Python</code></pre><h2 id="2-4-字符串处理函数"><a href="#2-4-字符串处理函数" class="headerlink" title="2.4 字符串处理函数"></a>2.4 字符串处理函数</h2><h3 id="2-4-1-字符串的长度"><a href="#2-4-1-字符串的长度" class="headerlink" title="2.4.1 字符串的长度"></a>2.4.1 字符串的长度</h3><ul><li>所含字符的个数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"python"</span></span><br><span class="line">len(s)</span><br></pre></td></tr></table></figure><pre><code>6</code></pre><h3 id="2-4-2-字符编码"><a href="#2-4-2-字符编码" class="headerlink" title="2.4.2 字符编码"></a>2.4.2 字符编码</h3><p><strong>将中文字符，英文字母，数字，特殊字符等转化成计算机可识别的二进制数</strong></p><ul><li>每个单一字符对应一个唯一且不重复的二进制编码</li><li>Python中使用的是Unicode编码</li></ul><p><strong>将字符转化为Unicode码——ord(字符)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(ord(<span class="string">"1"</span>))</span><br><span class="line">print(ord(<span class="string">"a"</span>))</span><br><span class="line">print(ord(<span class="string">"*"</span>))</span><br><span class="line">print(ord(<span class="string">"国"</span>))</span><br></pre></td></tr></table></figure><pre><code>49974222269</code></pre><p><strong>将Unicode码转化为字符——chr(Unicode码)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(chr(<span class="number">1010</span>))</span><br><span class="line">print(chr(<span class="number">49</span>))</span><br><span class="line">print(chr(<span class="number">22269</span>))</span><br></pre></td></tr></table></figure><pre><code>ϲ1国</code></pre><h2 id="2-5-字符串的处理方法"><a href="#2-5-字符串的处理方法" class="headerlink" title="2.5 字符串的处理方法"></a>2.5 字符串的处理方法</h2><h3 id="2-5-1-字符串的分割——str-split-分割字符"><a href="#2-5-1-字符串的分割——str-split-分割字符" class="headerlink" title="2.5.1 字符串的分割——str.split(分割字符)"></a>2.5.1 字符串的分割——str.split(分割字符)</h3><ul><li>返回一个列表</li><li>原字符串不变</li></ul><p><strong>上述特性适合以下所有字符串处理方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">languages = <span class="string">"Python C C++ Java PHP R"</span></span><br><span class="line">languages_list = languages.split(<span class="string">" "</span>)</span><br><span class="line">languages_list2 = languages.split(<span class="string">"C"</span>)</span><br><span class="line">print(languages_list)</span><br><span class="line">print(languages_list2)</span><br><span class="line">print(languages)</span><br></pre></td></tr></table></figure><pre><code>[&#39;Python&#39;, &#39;C&#39;, &#39;C++&#39;, &#39;Java&#39;, &#39;PHP&#39;, &#39;R&#39;][&#39;Python &#39;, &#39; &#39;, &#39;++ Java PHP R&#39;]Python C C++ Java PHP R</code></pre><h3 id="2-5-2-字符串的聚合——-quot-聚合字符-quot-join-可迭代数据类型"><a href="#2-5-2-字符串的聚合——-quot-聚合字符-quot-join-可迭代数据类型" class="headerlink" title="2.5.2 字符串的聚合——&quot;聚合字符&quot;.join(可迭代数据类型)"></a>2.5.2 字符串的聚合——<code>&quot;聚合字符&quot;.join(可迭代数据类型)</code></h3><ul><li>可迭代类型如:字符串、列表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"12345"</span></span><br><span class="line">s_join = <span class="string">","</span>.join(s)</span><br><span class="line">s_join</span><br></pre></td></tr></table></figure><pre><code>&#39;1,2,3,4,5&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># s = [1,2,3,4,5] 列表中元素必须是字符才可聚合</span></span><br><span class="line">s = [<span class="string">"13"</span>,<span class="string">"2"</span>,<span class="string">"3"</span>,<span class="string">"4"</span>,<span class="string">"5"</span>]</span><br><span class="line"><span class="string">"*"</span>.join(s)</span><br></pre></td></tr></table></figure><pre><code>&#39;13*2*3*4*5&#39;</code></pre><h3 id="2-5-3-删除两端特定字符——str-strip-要删除的字符"><a href="#2-5-3-删除两端特定字符——str-strip-要删除的字符" class="headerlink" title="2.5.3 删除两端特定字符——str.strip(要删除的字符)"></a>2.5.3 删除两端特定字符——<code>str.strip(要删除的字符)</code></h3><ul><li>strip从两端开始搜索，遇到指定字符执行删除操作，遇到非指定字符则搜索停止</li><li>类似的还有左删除<code>lstrip</code>和右删除<code>rstrip</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"       I have many blands       "</span></span><br><span class="line">print(s.strip(<span class="string">" "</span>))</span><br><span class="line">print(s.lstrip(<span class="string">" "</span>))</span><br><span class="line">print(s.rstrip(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure><pre><code>I have many blandsI have many blands              I have many blands</code></pre><h3 id="2-5-4-字符串的替换——str-replace-quot-被替换-quot-quot-替换成-quot"><a href="#2-5-4-字符串的替换——str-replace-quot-被替换-quot-quot-替换成-quot" class="headerlink" title="2.5.4 字符串的替换——str.replace(&quot;被替换&quot;,&quot;替换成&quot;)"></a>2.5.4 字符串的替换——<code>str.replace(&quot;被替换&quot;,&quot;替换成&quot;)</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"Python is coming"</span></span><br><span class="line">s1 = s.replace(<span class="string">"Python"</span>,<span class="string">"Py"</span>)</span><br><span class="line">print(s)</span><br><span class="line">print(s1)</span><br></pre></td></tr></table></figure><pre><code>Python is comingPy is coming</code></pre><h3 id="2-5-5-字符串统计——str-count-quot-待统计字符串-quot"><a href="#2-5-5-字符串统计——str-count-quot-待统计字符串-quot" class="headerlink" title="2.5.5 字符串统计——str.count(&quot;待统计字符串&quot;)"></a>2.5.5 字符串统计——<code>str.count(&quot;待统计字符串&quot;)</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"Python is an excellent language"</span></span><br><span class="line">print(<span class="string">"an:"</span>, s.count(<span class="string">"an"</span>))</span><br><span class="line">print(<span class="string">"e:"</span>, s.count(<span class="string">"e"</span>))</span><br></pre></td></tr></table></figure><pre><code>an: 2e: 4</code></pre><h3 id="2-5-6-字符串字母大小写"><a href="#2-5-6-字符串字母大小写" class="headerlink" title="2.5.6 字符串字母大小写"></a>2.5.6 字符串字母大小写</h3><ul><li><code>str.upper()# 字母全部大写</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"Python"</span></span><br><span class="line">print(s.upper())</span><br><span class="line">print(s)</span><br></pre></td></tr></table></figure><pre><code>PYTHONPython</code></pre><ul><li><code>str.lower()# 字母全部小写</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s.lower()</span><br></pre></td></tr></table></figure><pre><code>&#39;python&#39;</code></pre><ul><li><code>str.title()# 首字母大写</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">"PYTHON"</span></span><br><span class="line">s.title()</span><br></pre></td></tr></table></figure><pre><code>&#39;Python&#39;</code></pre><h1 id="第三部分-布尔类型-True-or-False"><a href="#第三部分-布尔类型-True-or-False" class="headerlink" title="第三部分 布尔类型 True or False"></a>第三部分 布尔类型 True or False</h1><h2 id="3-1-逻辑运算的结果"><a href="#3-1-逻辑运算的结果" class="headerlink" title="3.1 逻辑运算的结果"></a>3.1 逻辑运算的结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">10</span> </span><br><span class="line">print(a &gt; <span class="number">8</span>)</span><br><span class="line">print(a == <span class="number">12</span>)</span><br><span class="line">print(a &lt; <span class="number">5</span>)</span><br></pre></td></tr></table></figure><pre><code>TrueFalseFalse</code></pre><ul><li><code>any(),all()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(any([<span class="literal">False</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="literal">None</span>]))</span><br><span class="line">print(all([<span class="literal">False</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="literal">None</span>]))</span><br></pre></td></tr></table></figure><pre><code>TrueFalse</code></pre><h2 id="3-2-指示条件"><a href="#3-2-指示条件" class="headerlink" title="3.2 指示条件"></a>3.2 指示条件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">2800</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    m = eval(input(<span class="string">"请输入一个正整数："</span>))</span><br><span class="line">    <span class="keyword">if</span> m == n:</span><br><span class="line">        print(<span class="string">"bingo!"</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> m &gt; n:</span><br><span class="line">        print(<span class="string">"Too big"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"Too small"</span>)</span><br></pre></td></tr></table></figure><pre><code>请输入一个正整数：28Too small请输入一个正整数：5000Too big请输入一个正整数：2800bingo!</code></pre><h2 id="3-3-作为掩码"><a href="#3-3-作为掩码" class="headerlink" title="3.3 作为掩码"></a>3.3 作为掩码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>])</span><br><span class="line">print(x &gt; <span class="number">3</span>)</span><br><span class="line">print(x[x &gt; <span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>[False False False  True  True][5 7]</code></pre><h1 id="第四部分-类型判别及类型转换"><a href="#第四部分-类型判别及类型转换" class="headerlink" title="第四部分 类型判别及类型转换"></a>第四部分 类型判别及类型转换</h1><h2 id="4-1-类型判别"><a href="#4-1-类型判别" class="headerlink" title="4.1 类型判别"></a>4.1 类型判别</h2><ul><li>type(变量)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">age = <span class="number">20</span> </span><br><span class="line">name = <span class="string">"Ada"</span></span><br><span class="line">print(type(age))</span><br><span class="line">print(type(name))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;int&#39;&gt;&lt;class &#39;str&#39;&gt;</code></pre><ul><li>isinstance(object, class)，<strong>承认继承关系</strong></li><li>变量类型是预判类型的子类型即为真，否则为假</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(isinstance(age, int))</span><br><span class="line">print(isinstance(age, object))</span><br><span class="line">print(isinstance(name, object)) <span class="comment"># object是老祖宗</span></span><br></pre></td></tr></table></figure><pre><code>TrueTrueTrue</code></pre><ul><li>字符串检查方法</li></ul><figure class="highlight plain"><figcaption><span>字符是否只由数字组成```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">age &#x3D; &quot;20&quot;</span><br><span class="line">name &#x3D; &quot;Ada&quot;</span><br><span class="line">print(age.isdigit())</span><br><span class="line">print(name.isdigit())</span><br></pre></td></tr></table></figure><pre><code>TrueFalse</code></pre><figure class="highlight plain"><figcaption><span>字符是否只由字母组成```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">name.isalpha()</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight plain"><figcaption><span>字符是否只由数字和字母组成```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">&quot;Ada20&quot;.isalnum() # 比如可用于判断用户名是否合法</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><h2 id="4-2-类型转换"><a href="#4-2-类型转换" class="headerlink" title="4.2 类型转换"></a>4.2 类型转换</h2><ul><li>数字类型转字符串<code>str(数字类型)</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">age = <span class="number">20</span></span><br><span class="line">print(<span class="string">"My age is "</span> + str(age))</span><br></pre></td></tr></table></figure><pre><code>My age is 20</code></pre><ul><li>仅有数字组成的字符串转数字<code>int(),float(),eval()</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">s1 = <span class="string">"20"</span></span><br><span class="line">s2 = <span class="string">"10.1"</span></span><br><span class="line">print(int(s1))</span><br><span class="line"><span class="comment">#print(int(s2))</span></span><br><span class="line">print(float(s2))</span><br><span class="line">print(eval(s1))</span><br></pre></td></tr></table></figure><pre><code>2010.120</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deepshape_python基础2</title>
      <link href="/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%802/"/>
      <url>/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%802/</url>
      
        <content type="html"><![CDATA[<p><strong>高级语言：</strong></p><ul><li>按执行方式：<ul><li>编译型：整个代码一次性进行翻译，执行时是一个整体在执行</li><li>解释型：执行时是一句一句在执行</li></ul></li><li>按类型声明：<ul><li>动态语言：变量可以随时定义随时用，不需要事先声明其是什么类型</li><li>静态语言：需要事先声明该变量是什么类型</li></ul></li></ul><p><strong>python属于解释型、动态语言，所以相比执行起来比较慢</strong></p><h1 id="第一部分-数据类型"><a href="#第一部分-数据类型" class="headerlink" title="第一部分 数据类型"></a>第一部分 数据类型</h1><h2 id="1-基本类型：数字、字符串、布尔"><a href="#1-基本类型：数字、字符串、布尔" class="headerlink" title="1.基本类型：数字、字符串、布尔"></a>1.基本类型：数字、字符串、布尔</h2><h3 id="1-1-数字类型"><a href="#1-1-数字类型" class="headerlink" title="1.1 数字类型"></a>1.1 数字类型</h3><ul><li>int整型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;int&#39;&gt;</code></pre><ul><li>float浮点型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="number">2.0</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;float&#39;&gt;</code></pre><ul><li>complex复数，a+bj</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="number">3</span>+<span class="number">4j</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;complex&#39;&gt;</code></pre><h3 id="1-2-字符串类型"><a href="#1-2-字符串类型" class="headerlink" title="1.2 字符串类型"></a>1.2 字符串类型</h3><ul><li>str字符串，视作文本</li><li>组成：由数字、字母、空格、其他字符等组合而成</li><li>表达：用””或’’</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(<span class="string">"python 123 @#$^&amp;(())"</span>))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;str&#39;&gt;</code></pre><h3 id="1-3-布尔类型"><a href="#1-3-布尔类型" class="headerlink" title="1.3 布尔类型"></a>1.3 布尔类型</h3><ul><li>bool布尔类型</li><li>主要用于逻辑运算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">2</span> &gt; <span class="number">1</span></span><br><span class="line">print(y,type(y))</span><br></pre></td></tr></table></figure><pre><code>True &lt;class &#39;bool&#39;&gt;</code></pre><p><strong>上述类型均可定义单个数据，如果有一组数据，该如何表示？</strong></p><h2 id="2-组合类型：列表、元组、字典、集合"><a href="#2-组合类型：列表、元组、字典、集合" class="headerlink" title="2.组合类型：列表、元组、字典、集合"></a>2.组合类型：列表、元组、字典、集合</h2><h3 id="2-1-列表"><a href="#2-1-列表" class="headerlink" title="2.1 列表"></a>2.1 列表</h3><ul><li>list列表，<strong>序列类型（即数据有位置顺序）</strong></li><li><p>表示方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">a &#x3D; [1,2,3]</span><br><span class="line">a[0]&#x3D;2 # 列表元素可修改</span><br><span class="line">print(a[0])</span><br><span class="line">print(type(a))</span><br></pre></td></tr></table></figure><p>  2</p>  <class 'list'></li></ul><h3 id="2-2-元组"><a href="#2-2-元组" class="headerlink" title="2.2 元组"></a>2.2 元组</h3><ul><li>tuple元组，序列类型</li><li>表示方式：<code>(data1,data2,...)</code></li><li><strong>元素不支持修改——不可变的列表</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># b[0]=2,会报错，因为元组元素不支持修改</span></span><br><span class="line">print(b[<span class="number">0</span>])</span><br><span class="line">print(type(b))</span><br></pre></td></tr></table></figure><pre><code>1&lt;class &#39;tuple&#39;&gt;</code></pre><h3 id="2-3-字典"><a href="#2-3-字典" class="headerlink" title="2.3 字典"></a>2.3 字典</h3><ul><li>dict字典，<strong>映射类型（即通过键值对的映射实现数据存储和查找），字典内部是无序的</strong></li><li>表示方式：<code>{key1:value1,key2:value2,...}</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">student = &#123;<span class="number">201901</span>:<span class="string">"xiaoming"</span>, <span class="number">201902</span>:<span class="string">"xiaohong"</span>, <span class="number">201903</span>:<span class="string">"xiaoqiang"</span>&#125;</span><br><span class="line">print(student[<span class="number">201901</span>])</span><br><span class="line">print(type(student))</span><br></pre></td></tr></table></figure><pre><code>xiaoming&lt;class &#39;dict&#39;&gt;</code></pre><h3 id="2-4-集合"><a href="#2-4-集合" class="headerlink" title="2.4 集合"></a>2.4 集合</h3><ul><li>set集合，<strong>一系列互不相等元素的集合，无序</strong></li><li>表示方式：<code>{data1,data2,...}</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c = &#123;<span class="string">"xiaoming"</span>, <span class="string">"xiaohong"</span>, <span class="string">"xiaoming"</span>&#125;</span><br><span class="line">print(c) <span class="comment"># 集合中同一元素会自动删除</span></span><br><span class="line">print(type(c))</span><br></pre></td></tr></table></figure><pre><code>{&#39;xiaohong&#39;, &#39;xiaoming&#39;}&lt;class &#39;set&#39;&gt;</code></pre><p><strong>在程序中，如何引用数据？</strong></p><ul><li>通俗的处理办法：赋值给一个变量</li></ul><h1 id="第二部分-变量"><a href="#第二部分-变量" class="headerlink" title="第二部分 变量"></a>第二部分 变量</h1><h2 id="1-变量的概念"><a href="#1-变量的概念" class="headerlink" title="1.变量的概念"></a>1.变量的概念</h2><ul><li>“量”：实实在在的对象</li><li>“变”：可变性，增删查改等</li><li>变量定义而要素：变量名、赋值</li></ul><h2 id="2-变量的命名"><a href="#2-变量的命名" class="headerlink" title="2. 变量的命名"></a>2. 变量的命名</h2><h3 id="2-1哪些可以用来做变量名"><a href="#2-1哪些可以用来做变量名" class="headerlink" title="2.1哪些可以用来做变量名"></a>2.1哪些可以用来做变量名</h3><ul><li>大写字母、小写字母、数字、下划线、汉字及其组合</li><li>严格区分大小写</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python_is_第<span class="number">1</span>名 = <span class="literal">True</span></span><br></pre></td></tr></table></figure><ul><li>首字符不能是数字</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>_fruit = <span class="string">"apple"</span></span><br></pre></td></tr></table></figure><pre><code>  File &quot;&lt;ipython-input-11-e3b1d93d01a0&gt;&quot;, line 1    1_fruit = &quot;apple&quot;     ^SyntaxError: invalid token</code></pre><ul><li>变量名中间不能有空格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my fruit = <span class="string">"apple"</span></span><br></pre></td></tr></table></figure><ul><li>不能与33个Python保留字相同<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#and,as,assert,break,class,continue,def,del,elif,else,except,</span></span><br><span class="line"><span class="comment">#False,finally,for,from,global,if,import,in,is,lambda,None,nonlocal,</span></span><br><span class="line"><span class="comment">#not,or,pass,raise,return,True,try,while,with,yield</span></span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> = <span class="literal">True</span></span><br></pre></td></tr></table></figure><h3 id="2-3-变量名定义技巧"><a href="#2-3-变量名定义技巧" class="headerlink" title="2.3 变量名定义技巧"></a>2.3 变量名定义技巧</h3><ul><li><p>变量名尽可能有实际意义，表征数据的某种特性</p></li><li><p>用下划线(多用于变量和函数名）。变量名由多个单词组成，用_连接多个单词</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">age_of_students = [<span class="number">17</span>,<span class="number">18</span>,<span class="number">19</span>]</span><br></pre></td></tr></table></figure><ul><li>驼峰体（多用于类名）。变量名由多个单词组成，单词首字母大写</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AgeOfStudents</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><ul><li><p>尽量避免用中文和拼音做变量名</p></li><li><p>特殊的变量：常量（如Π，e），变量名所有字母均大写</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAX_ITERATION = <span class="number">1000</span></span><br></pre></td></tr></table></figure><h2 id="3-变量的赋值"><a href="#3-变量的赋值" class="headerlink" title="3.变量的赋值"></a>3.变量的赋值</h2><h3 id="3-1-一般赋值"><a href="#3-1-一般赋值" class="headerlink" title="3.1 一般赋值"></a>3.1 一般赋值</h3><ul><li>通过等号自右向左赋值</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span> + <span class="number">2</span></span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>3</code></pre><h3 id="3-2-增量赋值"><a href="#3-2-增量赋值" class="headerlink" title="3.2 增量赋值"></a>3.2 增量赋值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">10</span></span><br><span class="line"><span class="comment"># x = x + 10</span></span><br><span class="line">x += <span class="number">10</span></span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>20</code></pre><h3 id="3-3-打包赋值"><a href="#3-3-打包赋值" class="headerlink" title="3.3 打包赋值"></a>3.3 打包赋值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x, y = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">print(x, y)</span><br><span class="line">x, y = y, x <span class="comment"># 两个值互换</span></span><br><span class="line">print(x, y)</span><br></pre></td></tr></table></figure><pre><code>1 22 1</code></pre><h1 id="第三部分-控制流程"><a href="#第三部分-控制流程" class="headerlink" title="第三部分 控制流程"></a>第三部分 控制流程</h1><h2 id="1-顺序流程"><a href="#1-顺序流程" class="headerlink" title="1.顺序流程"></a>1.顺序流程</h2><ul><li>自上向下依次执行</li></ul><p><strong>示例：实现1到5的整数求和</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># res = 1 + 2 + 3 + 4 + 5</span></span><br><span class="line">res = <span class="number">0</span> </span><br><span class="line">res += <span class="number">1</span></span><br><span class="line">res += <span class="number">2</span></span><br><span class="line">res += <span class="number">3</span></span><br><span class="line">res += <span class="number">4</span></span><br><span class="line">res += <span class="number">5</span></span><br><span class="line">res</span><br></pre></td></tr></table></figure><pre><code>15</code></pre><h2 id="2-循环流程——遍历循环（for）"><a href="#2-循环流程——遍历循环（for）" class="headerlink" title="2.循环流程——遍历循环（for）"></a>2.循环流程——遍历循环（for）</h2><p><strong>主要形式：</strong></p><ul><li>for 元素 in 可迭代对象:</li></ul><p>　　　执行语句</p><p><strong>执行过程：</strong></p><ul><li>从可迭代对象中，依次取出每一个元素，并进行相应的操作</li></ul><p><strong>示例：实现1到5的整数求和</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]:</span><br><span class="line">    res += i</span><br><span class="line">res</span><br></pre></td></tr></table></figure><pre><code>15</code></pre><h2 id="3-循环流程——无限循环（while）"><a href="#3-循环流程——无限循环（while）" class="headerlink" title="3.循环流程——无限循环（while）"></a>3.循环流程——无限循环（while）</h2><p><strong>主要形式：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> 判断条件:</span><br><span class="line">    条件为真，执行语句</span><br><span class="line"><span class="comment">#条件为假，while循环结束</span></span><br></pre></td></tr></table></figure></p><p><strong>示例：实现1到5的整数求和</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> i &lt;= <span class="number">5</span>:</span><br><span class="line">    res += i</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">res</span><br></pre></td></tr></table></figure><pre><code>15</code></pre><h2 id="4-分支流程（if）"><a href="#4-分支流程（if）" class="headerlink" title="4.分支流程（if）"></a>4.分支流程（if）</h2><p><strong>最简单的形式：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> 判断条件:</span><br><span class="line">    条件为真，执行语句</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    条件为假，执行语句</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">age = <span class="number">18</span></span><br><span class="line"><span class="keyword">if</span> age &gt; <span class="number">22</span>:</span><br><span class="line">    print(<span class="string">"可以结婚啦"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"No"</span>)</span><br></pre></td></tr></table></figure><pre><code>No</code></pre><h1 id="第四部分-输入输出"><a href="#第四部分-输入输出" class="headerlink" title="第四部分 输入输出"></a>第四部分 输入输出</h1><h2 id="1-数据从哪里来？"><a href="#1-数据从哪里来？" class="headerlink" title="1.数据从哪里来？"></a>1.数据从哪里来？</h2><ol><li><p>外部文件导入</p><ul><li>从本地硬盘、网络端读入等</li><li>该部分内容见第八章</li></ul></li><li><p>程序中定义</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">age = <span class="number">18</span></span><br><span class="line">name = <span class="string">"Tom"</span></span><br></pre></td></tr></table></figure><ol><li>动态交互输入input<ul><li>在程序运行的过程中进行输入</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = input(<span class="string">"请输入一个数字："</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(type(x)) <span class="comment"># 可验证通过input定义的变量是一个str类型</span></span><br></pre></td></tr></table></figure><pre><code>请输入一个数字：33&lt;class &#39;str&#39;&gt;</code></pre><ul><li>用eval()去掉引号</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = eval(input(<span class="string">"请输入一个数字："</span>))</span><br><span class="line">print(x)</span><br><span class="line">print(type(x))</span><br></pre></td></tr></table></figure><pre><code>请输入一个数字：33&lt;class &#39;int&#39;&gt;</code></pre><h2 id="2-数据到哪里去？"><a href="#2-数据到哪里去？" class="headerlink" title="2.数据到哪里去？"></a>2.数据到哪里去？</h2><ol><li>存储到本地硬盘或网络端<ul><li>该部分内容见第八章</li></ul></li><li>打印输入print<ul><li>直接打印数据</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Hello, world"</span>)</span><br></pre></td></tr></table></figure><pre><code>Hello, world</code></pre><ul><li>打印变量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1024</span></span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><pre><code>1024</code></pre><ul><li>print默认换行，若不想换行，则用<code>end=</code>控制</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">1</span>)</span><br><span class="line">print(<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"--------分割线---------"</span>)</span><br><span class="line">print(<span class="number">1</span>, end=<span class="string">" "</span>)</span><br><span class="line">print(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>12--------分割线---------1 2</code></pre><ul><li>若需要一些复杂输出：如几个变量一起组合输出</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PI = <span class="number">3.1415926</span></span><br><span class="line">E = <span class="number">2.71828</span></span><br><span class="line">print(<span class="string">"PI = "</span>, PI, <span class="string">"E = "</span>, E)</span><br></pre></td></tr></table></figure><pre><code>PI =  3.1415926 E =  2.71828</code></pre><ol><li>格式化输出方法format<ul><li>基本格式：<code>&quot;字符{0}字符{1}字符&quot;.format(v0,v1)</code>v0,v1会依次填入前面{}中</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"PI = &#123;&#125;, E = &#123;&#125;"</span>.format(PI, E))</span><br><span class="line">print(<span class="string">"-------分割线-------"</span>)</span><br><span class="line">print(<span class="string">"PI = &#123;1&#125;, E = &#123;0&#125;"</span>.format(PI, E)) <span class="comment"># &#123;&#125;中的数字用于指定填入该位置的变量</span></span><br></pre></td></tr></table></figure><pre><code>PI = 3.1415926, E = 2.71828-------分割线-------PI = 2.71828, E = 3.1415926</code></pre><ul><li>再进一步 修饰性输出<ol><li>填充输出 <code>&quot;{0:_^20}&quot;.format(PI)</code>{}中，冒号之后表示开始修饰性输出，下划线_表示用其进行填充，^表示居中输出（&lt;居左输出，&gt;居右输出），20表示输出宽度。</li></ol></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"&#123;0:_&gt;20&#125;"</span>.format(PI))</span><br><span class="line">print(<span class="string">"&#123;:*&lt;20&#125;"</span>.format(PI))</span><br></pre></td></tr></table></figure><pre><code>___________3.14159263.1415926***********</code></pre><ol><li>数字千分位分隔符<ul><li>显示1,000,000</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"&#123;0:,&#125;"</span>.format(<span class="number">1000000</span>))</span><br><span class="line">print(<span class="string">"-------分割线------"</span>)</span><br><span class="line">print(<span class="string">"&#123;0:&amp;^20,&#125;"</span>.format(<span class="number">1000000</span>)) <span class="comment"># 注意填充指令必须在千分位分隔符之前写出</span></span><br></pre></td></tr></table></figure><pre><code>1,000,000-------分割线------&amp;&amp;&amp;&amp;&amp;1,000,000&amp;&amp;&amp;&amp;&amp;&amp;</code></pre><ol><li>浮点数简化输出<ul><li>留2位小数</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"&#123;0:.2f&#125;"</span>.format(PI))</span><br></pre></td></tr></table></figure><pre><code>3.14</code></pre><ul><li>按百分数输出</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"&#123;0:.1%&#125;"</span>.format(<span class="number">0.818727</span>)) <span class="comment"># 保留一位小数的百分数输出</span></span><br></pre></td></tr></table></figure><pre><code>81.9%</code></pre><ul><li>科学计数法输出</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"&#123;0:.2e&#125;"</span>.format(<span class="number">0.818727</span>))</span><br></pre></td></tr></table></figure><pre><code>8.19e-01</code></pre><ol><li>整数的进制转换输出<ul><li>十进制整数转二进制、unicode码、十进制、八进制、十六进制输出</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"二进制&#123;0:b&#125;,Unicode码&#123;0:c&#125;,十进制&#123;0:d&#125;,八进制&#123;0:o&#125;,十六进制&#123;0:x&#125;"</span>.format(<span class="number">450</span>))</span><br></pre></td></tr></table></figure><pre><code>二进制111000010,Unicode码ǂ,十进制450,八进制702,十六进制1c2</code></pre><h1 id="第五部分-程序格式"><a href="#第五部分-程序格式" class="headerlink" title="第五部分 程序格式"></a>第五部分 程序格式</h1><ol><li>行最大长度<ul><li>所有行限制的最大字符数为79</li></ul></li><li>缩进<ul><li>用缩进来表示语句间的逻辑</li><li>在for,while,if,def,class等：之后开始进行缩进，表明后续代码与前句之间的从属关系</li><li>缩进量：4字符</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]:</span><br><span class="line">    print(i)</span><br><span class="line">print(<span class="string">"打印结束"</span>)</span><br></pre></td></tr></table></figure><pre><code>123打印结束</code></pre><ol><li>使用空格<ul><li>二元运算符两边加一个空格</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">2</span></span><br><span class="line">x += <span class="number">3</span></span><br></pre></td></tr></table></figure><ul><li>使用不同优先级的运算符，考虑在最低优先级的运算符周围添加空格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = x*<span class="number">2</span> - <span class="number">1</span></span><br><span class="line">z = x*x + y*y</span><br><span class="line">c = (x+y) * (x-y)</span><br></pre></td></tr></table></figure><ul><li>在逗号后使用空格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x, y = <span class="number">1</span>, <span class="number">2</span></span><br></pre></td></tr></table></figure><ol><li>避免使用空格<ul><li>在指定关键字参数或默认参数值的时候，不要在=附近加空格</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n=<span class="number">1</span>, m=<span class="number">2</span>)</span>:</span></span><br><span class="line">    print(n, m)</span><br></pre></td></tr></table></figure><p><strong>小结</strong></p><ol><li>以上属于PEP8格式指南的部分内容，养成良好编码规范</li><li>格式约定目的：<ul><li>使代码风格一致</li><li>提升代码可读性</li></ul></li><li>不要死板执行格式规范<ul><li>项目规范优先</li></ul></li><li>注释<ul><li>单行注释</li><li>格式：<code>#注释内容</code></li><li>多行注释</li><li>格式：<code>&quot;&quot;&quot;注释内容，可分行&quot;&quot;&quot;</code></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习框架搭建课程三（网络节点封装与调用）</title>
      <link href="/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/"/>
      <url>/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="defaultdict用法"><a href="#defaultdict用法" class="headerlink" title="defaultdict用法"></a>defaultdict用法</h2><ul><li><strong>普通的字典时，用法一般是dict={},添加元素的只需要dict[element] =value即，调用的时候也是如此，dict[element] = xxx,但前提是element在字典里，如果不在字典里就会报错。</strong></li><li><strong>defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。</strong><ul><li><strong>defaultdict接受一个工厂函数作为参数，如下来构造：</strong></li><li><strong>dict =defaultdict( factory_function)</strong></li><li><strong>factory_function可以是list、set、str等等，作用是当key不存在时，返回的是工厂函数的默认值，比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0</strong></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 节点类中，forward方法用于计算前向传播过程中每个节点的值value，backward方法用于计算反向传播过程中每个节点的输入相对于网络loss的偏导</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span> <span class="comment"># 节点基类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs=[], name=None, is_trainable=True)</span>:</span> <span class="comment"># inputs为当前Node的输入节点</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        self.outputs = []</span><br><span class="line">        self.name = name</span><br><span class="line">        self.value = <span class="literal">None</span></span><br><span class="line">        self.is_trainable = is_trainable</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> input_ <span class="keyword">in</span> self.inputs: <span class="comment"># 当前节点的输入也是节点类，</span></span><br><span class="line">                                   <span class="comment"># 这里把当前节点写入其输入节点的输出属性</span></span><br><span class="line">            input_.outputs.append(self)</span><br><span class="line">            </span><br><span class="line">        self.gradients = defaultdict(int)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError <span class="comment"># python标准异常之一:尚未处理的方法</span></span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span> <span class="comment"># __repr__() 方法是类的实例化对象用来做</span></span><br><span class="line">                        <span class="comment">#“自我介绍”的方法，默认情况下，它会返</span></span><br><span class="line">                        <span class="comment">#回当前对象的“类名+object at+内存地址”，</span></span><br><span class="line">                        <span class="comment">#而如果对该方法进行重写，可以为其制作自定</span></span><br><span class="line">                        <span class="comment">#义的自我描述信息</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Placeholder</span><span class="params">(Node)</span>:</span> </span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    该节点（占位符）用来作为图的输入，当运行forward函数时，对其赋值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, is_trainable=True)</span>:</span></span><br><span class="line">        Node.__init__(self, name=name, is_trainable=is_trainable)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, value=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: self.value = value</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            self.gradients[self] = n.gradients[self] * <span class="number">1</span>  </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=None, weight=None, bias=None, name=None, is_trainable=False)</span>:</span> <span class="comment"># w * x + b</span></span><br><span class="line">        Node.__init__(self, [x, weight, bias], name=name)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        k, x, b = self.inputs[<span class="number">1</span>], self.inputs[<span class="number">0</span>], self.inputs[<span class="number">2</span>]</span><br><span class="line">        </span><br><span class="line">        self.value = k.value * x.value + b.value</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        k, x, b = self.inputs[<span class="number">1</span>], self.inputs[<span class="number">0</span>], self.inputs[<span class="number">2</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self] </span><br><span class="line">            </span><br><span class="line">            self.gradients[k] = grad_cost * x.value</span><br><span class="line">            self.gradients[b] = grad_cost * <span class="number">1</span></span><br><span class="line">            self.gradients[x] = grad_cost * k.value</span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sigmoid</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [x], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.x = self.inputs[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1</span> + np.exp(<span class="number">-1</span> * x))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.value = self._sigmoid(self.x.value)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._sigmoid(self.x.value) * (<span class="number">1</span> - self._sigmoid(self.x.value))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            self.gradients[self.x] = grad_cost * self.partial()             </span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Relu</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [x], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.x = x</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.value = self.x.value * (self.x.value &gt; <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            self.gradients[self.x] = grad_cost * (self.x.value &gt; <span class="number">0</span>) </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">L2_Loss</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, y, y_hat, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [y, y_hat], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.y = y</span><br><span class="line">        self.y_hat = y_hat</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span>        </span><br><span class="line">        y_v = np.array(self.y.value)</span><br><span class="line">        yhat_v = np.array(self.y_hat.value)</span><br><span class="line">        self.value = np.mean((y_v - yhat_v) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 1/n sum (y- yhat)**2</span></span><br><span class="line">        y_v = np.array(self.y.value)</span><br><span class="line">        yhat_v = np.array(self.y_hat.value)</span><br><span class="line">        self.gradients[self.y] = <span class="number">2</span> * np.mean((y_v - yhat_v))</span><br><span class="line">        self.gradients[self.y_hat] = <span class="number">-2</span> * np.mean((y_v - yhat_v))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toplogic</span><span class="params">(graph)</span>:</span> <span class="comment"># 用于对人为设置的计算图排序，返回传播过程的节点顺序列表</span></span><br><span class="line">    sorted_node = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(graph) &gt; <span class="number">0</span>:</span><br><span class="line">        all_inputs = []</span><br><span class="line">        all_outputs = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> graph:</span><br><span class="line">            all_inputs += graph[n] <span class="comment"># 收集所有有输入的节点</span></span><br><span class="line">            all_outputs.append(n) <span class="comment"># 收集所有有输出的节点</span></span><br><span class="line">            </span><br><span class="line">        all_inputs = set(all_inputs)</span><br><span class="line">        all_outputs = set(all_outputs)</span><br><span class="line"></span><br><span class="line">        need_remove = all_outputs - all_inputs <span class="comment"># 有输出的节点集合</span></span><br><span class="line">                                               <span class="comment"># -有输入的节点集合</span></span><br><span class="line">                                               <span class="comment"># =只有输出，没有输</span></span><br><span class="line">                                               <span class="comment"># 入的节点集合</span></span><br><span class="line">        <span class="comment">#print(need_remove)</span></span><br><span class="line">        <span class="keyword">if</span> len(need_remove) &gt; <span class="number">0</span>:</span><br><span class="line">            node = random.choice(list(need_remove))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> len(graph) == <span class="number">1</span>: temp = graph[node]</span><br><span class="line">            graph.pop(node) <span class="comment"># 删除该节点</span></span><br><span class="line">            sorted_node.append(node)</span><br><span class="line">            <span class="keyword">if</span> len(graph) &lt; <span class="number">1</span>: sorted_node += temp</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> sorted_node</span><br></pre></td></tr></table></figure><h2 id="isinstance-object-classinfo"><a href="#isinstance-object-classinfo" class="headerlink" title="isinstance(object, classinfo)"></a>isinstance(object, classinfo)</h2><ul><li>isinstance() 函数来判断一个对象是否是一个已知的类型，类似 type()</li><li>isinstance() 与 type() 区别：<ul><li>type() 不会认为子类是一种父类类型，不考虑继承关系。</li><li>isinstance() 会认为子类是一种父类类型，考虑继承关系。</li><li>如果要判断两个类型是否相同推荐使用 isinstance()</li></ul></li><li>object — 实例对象</li><li>classinfo — 可以是直接或间接类名、基本类型或者由它们组成的元组</li><li>如果对象的类型与参数二的类型（classinfo）相同则返回 True，否则返回 False</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_feed_dict_to_graph</span><span class="params">(feed_dict)</span>:</span> <span class="comment"># feed_dict是整个网络初始化时的输入节点字典，其中key为输入节点，value为对应的输入值</span></span><br><span class="line">    computing_graph = defaultdict(list)</span><br><span class="line">    </span><br><span class="line">    nodes = [n <span class="keyword">for</span> n <span class="keyword">in</span> feed_dict] <span class="comment"># 从feed_dict中取出key值构成节点列表</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> nodes:</span><br><span class="line">        n = nodes.pop(<span class="number">0</span>) <span class="comment"># 返回并删除nodes列表中的第一个元素</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> isinstance(n, Placeholder): <span class="comment"># 判断该元素是否是Placeholder类，Placeholder类为输入节点类，</span></span><br><span class="line">                                       <span class="comment"># 若为Placeholder类，则将feed_dict中对应的value赋给该元素。</span></span><br><span class="line">            n.value = feed_dict[n]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">in</span> computing_graph: <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> n.outputs: <span class="comment"># 对该元素的输出使用for循环，将其输出添加至computing_graph字典中对应该元素的value列表中，</span></span><br><span class="line">                            <span class="comment"># 表示该键值对满足一对输入输出节点关系。</span></span><br><span class="line">            computing_graph[n].append(m)</span><br><span class="line">            nodes.append(m)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> computing_graph <span class="comment"># 返回的computing_graph即为人为设置的网络结构计算图</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topological_sort_feed_dict</span><span class="params">(feed_dict)</span>:</span> <span class="comment"># 拓扑排序，返回网络传播过程各节点的排列顺序列表</span></span><br><span class="line">    graph = convert_feed_dict_to_graph(feed_dict)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> toplogic(graph)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_and_backward</span><span class="params">(graph_order, monitor=False)</span>:</span> <span class="comment"># 对graph_order列表中的节点依次进行前向和反向传播，更新每个节点的值和梯度</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph_order:</span><br><span class="line">        <span class="keyword">if</span> monitor:</span><br><span class="line">            print(<span class="string">'forward computing -- &#123;&#125;'</span>.format(node))</span><br><span class="line">        node.forward()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph_order[::<span class="number">-1</span>]:</span><br><span class="line">        <span class="keyword">if</span> monitor:</span><br><span class="line">            print(<span class="string">'backward computing -- &#123;&#125;'</span>.format(node))</span><br><span class="line">        node.backward()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(graph, learning_rate=<span class="number">1e-2</span>)</span>:</span> <span class="comment"># 权重优化函数，对is_trainable==True的节点进行负梯度方向的优化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> t.is_trainable:</span><br><span class="line">            t.value += <span class="number">-1</span> * learning_rate * t.gradients[t]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">data = load_boston()</span><br><span class="line">X_, y_ = data[<span class="string">'data'</span>], data[<span class="string">'target'</span>] <span class="comment"># 分别赋值</span></span><br><span class="line">X_rm = X_[:,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别给各权重设定初始值</span></span><br><span class="line">w1_, b1_ = np.random.normal(), np.random.normal() </span><br><span class="line">w2_, b2_ = np.random.normal(), np.random.normal()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义所有Placeholder类的输入节点</span></span><br><span class="line">X, y = Placeholder(name=<span class="string">'X'</span>, is_trainable=<span class="literal">False</span>), Placeholder(name=<span class="string">'y'</span>, is_trainable=<span class="literal">False</span>)</span><br><span class="line">w1, b1 = Placeholder(name=<span class="string">'w1'</span>), Placeholder(name=<span class="string">'b1'</span>)</span><br><span class="line">w2, b2 = Placeholder(name=<span class="string">'w2'</span>), Placeholder(name=<span class="string">'b2'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型，根据前面各种节点类方法的定义，以下声明实例的方法会自动设置好各个节点间的输入输出关系</span></span><br><span class="line">output1 = Linear(X, w1, b1, name=<span class="string">'Linear-01'</span>,)</span><br><span class="line">output2 = Sigmoid(output1, name=<span class="string">'activation'</span>)</span><br><span class="line">y_hat = Linear(output2, w2, b2, name=<span class="string">'y_hat'</span>)</span><br><span class="line">cost = L2_Loss(y, y_hat, name=<span class="string">'cost'</span>)</span><br><span class="line"></span><br><span class="line">feed_dict = &#123; <span class="comment"># 建立输入节点和其初始值的对应关系</span></span><br><span class="line">    X: X_rm,</span><br><span class="line">    y: y_,</span><br><span class="line">    w1: w1_,</span><br><span class="line">    w2: w2_,</span><br><span class="line">    b1: b1_,</span><br><span class="line">    b2: b2_,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">graph_sort = topological_sort_feed_dict(feed_dict)</span><br><span class="line"></span><br><span class="line">epoch = <span class="number">1000</span></span><br><span class="line">batch_num = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line">losses = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> tqdm(range(epoch)):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(batch_num): <span class="comment"># 每次随机对一个点的loss进行优化</span></span><br><span class="line">        index = np.random.choice(range(len(X_rm)))</span><br><span class="line">        X.value = X_rm[index]</span><br><span class="line">        y.value = y_[index]</span><br><span class="line">        </span><br><span class="line">        forward_and_backward(graph_sort, monitor=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        optimize(graph_sort, learning_rate)</span><br><span class="line">        </span><br><span class="line">        loss += cost.value</span><br><span class="line">    <span class="comment">#print(loss)</span></span><br><span class="line">    losses.append(loss / batch_num)</span><br></pre></td></tr></table></figure><pre><code>HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value=&#39;&#39;)))</code></pre><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(x, graph)</span>:</span> <span class="comment"># 用训练结束后的模型推理</span></span><br><span class="line">    X.value = x</span><br><span class="line">    forward_and_backward(graph)</span><br><span class="line">    <span class="keyword">return</span> y_hat.value</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(losses)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fdde0fe6090&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/2e7788273e841246ed82ebc384201c0e.png" alt="output_14_1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_rm, y_)</span><br><span class="line">plot_x = np.linspace(min(X_rm), max(X_rm), <span class="number">1000</span>)</span><br><span class="line">plt.scatter(plot_x, [predict(x, graph_sort) <span class="keyword">for</span> x <span class="keyword">in</span> plot_x], s=<span class="number">30</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7fdde0a65690&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/464d16ea17f3526e25f38e70cac37000.png" alt="output_15_1"></p><h2 id="对前面建立的模型前向和反向传播过程可视化"><a href="#对前面建立的模型前向和反向传播过程可视化" class="headerlink" title="对前面建立的模型前向和反向传播过程可视化"></a>对前面建立的模型前向和反向传播过程可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">computing_graph = convert_feed_dict_to_graph(feed_dict)</span><br><span class="line">graph = nx.DiGraph(computing_graph)</span><br><span class="line">layout = nx.layout.spring_layout(graph)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visited_procedure</span><span class="params">(graph, position, visited_order, step, sub_plot_index=None, colors=<span class="params">(<span class="string">'red'</span>, <span class="string">'green'</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 将图graph按照访问顺序visited_order变换颜色</span></span><br><span class="line">    changed = visited_order[:step] <span class="keyword">if</span> step <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> visited_order</span><br><span class="line">    </span><br><span class="line">    before, after = colors</span><br><span class="line">    </span><br><span class="line">    color_map = [after <span class="keyword">if</span> c <span class="keyword">in</span> changed <span class="keyword">else</span> before <span class="keyword">for</span> c <span class="keyword">in</span> graph]</span><br><span class="line">    </span><br><span class="line">    nx.draw(graph, position, node_color=color_map, with_labels=<span class="literal">True</span>,ax=sub_plot_index)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(graph_sort)**<span class="number">0.5</span>)</span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(graph_sort)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, graph_sort, step=i, sub_plot_index=ax[ix])</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/7f8637596110340f2a255a77744622b8.png" alt="output_20_0"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(graph_sort)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(graph_sort)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, graph_sort[::<span class="number">-1</span>], step=i, sub_plot_index=ax[ix], colors=(<span class="string">'green'</span>,<span class="string">'red'</span>))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/aa59a48142b4f97c246628520f383729.png" alt="output_21_0"></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> framework </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）</title>
      <link href="/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%BA%8C%EF%BC%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%EF%BC%89/"/>
      <url>/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%BA%8C%EF%BC%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="Lesson2-反向传播-激活函数-图传播的拓扑结构"><a href="#Lesson2-反向传播-激活函数-图传播的拓扑结构" class="headerlink" title="Lesson2 反向传播 激活函数 图传播的拓扑结构"></a>Lesson2 反向传播 激活函数 图传播的拓扑结构</h1><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, y = load_boston()[<span class="string">'data'</span>],load_boston()[<span class="string">'target'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">room_index = <span class="number">5</span></span><br><span class="line">X_rm = X[:, room_index]</span><br></pre></td></tr></table></figure><h2 id="zip"><a href="#zip" class="headerlink" title="zip()"></a>zip()</h2><ul><li><strong>用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，这样做的好处是节约了不少的内存。</strong></li><li><strong>可以使用 list() 转换来输出列表</strong></li><li><strong>如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###############zip()示例################</span></span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">c = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">zipped = zip(a,b)</span><br><span class="line">print(zipped)</span><br><span class="line">print(list(zipped))</span><br><span class="line">print(list(zip(a,c)))</span><br><span class="line"></span><br><span class="line">a1, a2 = zip(*zip(a,b))</span><br><span class="line">print(a1, a2)</span><br></pre></td></tr></table></figure><pre><code>&lt;zip object at 0x7fd68191da00&gt;[(1, 4), (2, 5), (3, 6)][(1, 4), (2, 5), (3, 6)](1, 2, 3) (4, 5, 6)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(y, yhat)</span>:</span> </span><br><span class="line">    <span class="comment"># 如何定义loss函数，是一个单独的研究方向</span></span><br><span class="line">    <span class="comment"># loss尽量让它是一个凸函数</span></span><br><span class="line">    <span class="comment"># 凸函数上找到最小值或者最大值的情况，我们叫做优化问题optimize</span></span><br><span class="line">    <span class="comment"># Convex Optimization</span></span><br><span class="line">    sum_ = sum([(y_i - yhat_i) ** <span class="number">2</span> <span class="keyword">for</span> y_i, yhat_i <span class="keyword">in</span> zip(y, yhat)])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> sum_ / len(y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partial_k</span><span class="params">(x, y, yhat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span> * np.mean((np.array(y)-np.array(yhat))*np.array(x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partial_b</span><span class="params">(y, yhat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span> * np.mean(np.array(y)-np.array(yhat))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(x, k, b)</span>:</span> <span class="comment"># 本课将模型简化成了一种线性关系 </span></span><br><span class="line">    <span class="comment"># RNN, CNN, Batch_normalization</span></span><br><span class="line">    <span class="comment"># CNN</span></span><br><span class="line">    <span class="keyword">return</span> k * x + b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimizer</span><span class="params">(k, b, X_rm, y, price_predicted, learning_rate)</span>:</span></span><br><span class="line">    <span class="comment"># Adam, momentum...</span></span><br><span class="line">    k_gradient = partial_k(X_rm, y, price_predicted)</span><br><span class="line">    b_gradient = partial_b(y, price_predicted)</span><br><span class="line"></span><br><span class="line">    k = k + (<span class="number">-1</span> * k_gradient) * learning_rate</span><br><span class="line">    b = b + (<span class="number">-1</span> * b_gradient) * learning_rate</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> k, b</span><br><span class="line"></span><br><span class="line">trying_time = <span class="number">50000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Initialization Parameters</span></span><br><span class="line">k = random.random() * <span class="number">100</span> - <span class="number">200</span></span><br><span class="line">b = random.random() * <span class="number">100</span> - <span class="number">200</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(trying_time):</span><br><span class="line">    price_predicted = model(X_rm, k, b)</span><br><span class="line">    loss_value = loss(y, price_predicted)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'step:&#123;&#125;--k==&#123;&#125;, b==&#123;&#125;, loss=&#123;&#125;'</span>.format(i, k, b, loss_value))</span><br><span class="line">    k, b = optimizer(k, b, X_rm, y, price_predicted, learning_rate)</span><br></pre></td></tr></table></figure><pre><code>step:0--k==-139.97574080889325, b==-189.5565944077231, loss=1202989.4946001442step:1000--k==28.789202260854257, b==-159.9025443960182, loss=236.82742611841562step:2000--k==28.321423579850478, b==-156.92694900374082, loss=227.7541131560305step:3000--k==27.86475963738596, b==-154.02205577495837, loss=219.10685380752045step:4000--k==27.418946339739048, b==-151.1861847783419, loss=210.86564196457158step:5000--k==26.98372586823378, b==-148.41769599886837, loss=203.0114109414113step:6000--k==26.558846530140826, b==-145.7149883893845, loss=195.52598936255154step:7000--k==26.144062613120745, b==-143.07649894470254, loss=188.3920591218916step:8000--k==25.739134243125765, b==-140.5007017976972, loss=181.59311531592934step:9000--k==25.343827245678145, b==-137.98610733688074, loss=175.1134280583828step:10000--k==24.957913010444287, b==-135.5312613449428, loss=168.9380060878701step:11000--k==24.58116835902728, b==-133.1347441577636, loss=163.05256208446227step:12000--k==24.213375415900217, b==-130.7951698434049, loss=157.44347961485315step:13000--k==23.854321482406256, b==-128.51118540061006, loss=152.09778162967729step:14000--k==23.50379891375279, b==-126.28146997634929, loss=147.00310044009777step:15000--k==23.161604998928414, b==-124.10473410195712, loss=142.14764910419603step:16000--k==22.827541843472655, b==-121.97971894741703, loss=137.52019415696014step:17000--k==22.501416255031483, b==-119.90519559336649, loss=133.11002962078763step:18000--k==22.183039631632305, b==-117.87996432040093, loss=128.90695223637664step:19000--k==21.872227852613182, b==-115.90285391526179, loss=124.90123785668611step:20000--k==21.56880117214389, b==-113.97272099351123, loss=121.08361894936512step:21000--k==21.272584115277002, b==-112.08844933830095, loss=117.44526315559573step:22000--k==20.983405376468696, b==-110.24894925485091, loss=113.97775285574032step:23000--k==20.701097720511058, b==-108.4531569402683, loss=110.67306569452485step:24000--k==20.425497885818103, b==-106.70003386833821, loss=107.52355602069466step:25000--k==20.156446490009778, b==-104.9885661889324, loss=104.52193719820313step:26000--k==19.893787937739386, b==-103.31776414168878, loss=101.66126474801261step:27000--k==19.63737033071113, b==-101.68666148362233, loss=98.93492028149987step:28000--k==19.387045379835737, b==-100.09431493033665, loss=96.33659618829992step:29000--k==19.142668319473103, b==-98.53980361051134, loss=93.86028104315582step:30000--k==18.904097823713013, b==-97.02222853335356, loss=91.50024569802068step:31000--k==18.67119592464453, b==-95.54071206870042, loss=89.25103002722422step:32000--k==18.443827932567885, b==-94.09439743947698, loss=87.10743029504896step:33000--k==18.221862358101898, b==-92.68244822621246, loss=85.0644871164814step:34000--k==18.00517083614213, b==-91.30404788332926, loss=83.11747398328737step:35000--k==17.79362805162611, b==-89.95839926692656, loss=81.26188632886817step:36000--k==17.587111667062057, b==-88.64472417378221, loss=79.49343110659359step:37000--k==17.385502251780128, b==-87.36226289131133, loss=77.8080168575062step:38000--k==17.18868321286402, b==-86.11027375821422, loss=76.20174424440974step:39000--k==16.996540727724163, b==-84.88803273556643, loss=74.67089703044967step:40000--k==16.808963678272896, b==-83.6948329880994, loss=73.21193348130983step:41000--k==16.625843586663674, b==-82.52998447542974, loss=71.82147817113456step:42000--k==16.447074552556995, b==-81.39281355300069, loss=70.496314173216step:43000--k==16.272553191877268, b==-80.28266258250707, loss=69.23337561738542step:44000--k==16.10217857702466, b==-79.19888955157587, loss=68.02974059688358step:45000--k==15.935852178507512, b==-78.14086770248328, loss=66.88262440830098step:46000--k==15.773477807961688, b==-77.10798516969385, loss=65.78937310895009step:47000--k==15.61496156252368, b==-76.09964462601131, loss=64.7474573767608step:48000--k==15.460211770525754, b==-75.11526293713911, loss=63.754466658498906step:49000--k==15.309138938481153, b==-74.15427082444685, loss=62.80810359276205</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_rm, y)</span><br><span class="line">plt.plot(X_rm, model(X_rm, k, b), color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd68193f290&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/d4f5269fd9dd6c4a80e1b763c9eae2ea.png" alt="output_8_1"></p><h2 id="世界中真实的关系大多都不是简单的线性关系"><a href="#世界中真实的关系大多都不是简单的线性关系" class="headerlink" title="世界中真实的关系大多都不是简单的线性关系"></a>世界中真实的关系大多都不是简单的线性关系</h2><h2 id="我们能不能构建一些基本的模块，然后用模块来组合成复杂的函数"><a href="#我们能不能构建一些基本的模块，然后用模块来组合成复杂的函数" class="headerlink" title="我们能不能构建一些基本的模块，然后用模块来组合成复杂的函数?"></a>我们能不能构建一些基本的模块，然后用模块来组合成复杂的函数?</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span> <span class="comment"># basic sub-model : Transfer: Activation Function激活函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>,<span class="number">1000</span>)</span><br><span class="line">plt.plot(x, sigmoid(x))</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd6810a2a50&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/f1d501a38c207b1d18f7f27a57ac3a7d.png" alt="output_10_1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_linear</span><span class="params">(x)</span>:</span></span><br><span class="line">    k, b = np.random.normal(), np.random.normal()</span><br><span class="line">    <span class="keyword">return</span> k * x + b * x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_x</span><span class="params">(n)</span>:</span></span><br><span class="line">    max_, min_ = <span class="number">500</span>, <span class="number">-500</span></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(np.linspace(min_, max_, <span class="number">20000</span>), n)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    test_x = np.linspace(<span class="number">-200</span>, <span class="number">200</span>, <span class="number">2000</span>)</span><br><span class="line">    plt.plot(random_linear(sigmoid(random_linear(test_x))))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/828704e97975df77532808c409fb05ad.png" alt="output_13_0"></p><h2 id="理论上，所有的函数都可以用多层的线性函数-非线性变化来拟合"><a href="#理论上，所有的函数都可以用多层的线性函数-非线性变化来拟合" class="headerlink" title="理论上，所有的函数都可以用多层的线性函数+非线性变化来拟合"></a>理论上，所有的函数都可以用多层的线性函数+非线性变化来拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> x * (x &gt; <span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.tanh(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, relu(x))</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd680f39b10&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/83b771fa653af1ab06f5c34b5e2ec773.png" alt="output_18_1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, tanh(x))</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fd680fcb890&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/529615a8a6e631888d886345cadf464c.png" alt="output_19_1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">so_many_layers</span><span class="params">(layers, x)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(layers) == <span class="number">1</span>: <span class="keyword">return</span> layers[<span class="number">-1</span>](x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> so_many_layers(layers[<span class="number">1</span>:], layers[<span class="number">0</span>](x)) <span class="comment"># 递归</span></span><br></pre></td></tr></table></figure><h2 id="北大ACM教练指出算法里最有意义的三种方法"><a href="#北大ACM教练指出算法里最有意义的三种方法" class="headerlink" title="北大ACM教练指出算法里最有意义的三种方法"></a>北大ACM教练指出算法里最有意义的三种方法</h2><ol><li>随机模拟 Randomization</li><li>递归 Recursion</li><li>动态规划 Dynamic Programming</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layers = [random_linear, relu, random_linear, tanh, random_linear, sigmoid]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    plt.plot(so_many_layers(layers, x))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/4d8cbab7c469d6fbe94ff3410cfacdfc.png" alt="output_23_0"></p><ul><li>神经网络可理解成乐高积木</li><li>有一群人（最重要的一群人）发明新的乐高积木模块</li><li>还有一群人研究积木特别高的时候怎样不倒塌</li><li>还有人研究积木怎样按照我们的需求自己组合</li><li>还有一群人研究搭建好的积木怎么用或者如何用现在的积木模块构造想模仿的问题</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply</span><span class="params">(func1, func2)</span>:</span> <span class="keyword">return</span> <span class="keyword">lambda</span> x:func2(func1(x))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    plt.plot(reduce(apply, layers)(x))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/6a5a5bb5a692650d7503742c3f7d094c.png" alt="output_27_0"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">price</span><span class="params">(x, k, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> k * x + b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span><span class="params">(x, k1, b1)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> k1 * x + b1</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_partial</span><span class="params">(k, b, x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> k</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_partial</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sigmoid(x) * (<span class="number">1</span> - sigmoid(x)) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(x, k1, k2, b1, b2)</span>:</span></span><br><span class="line">    output1 = linear(x, k1, b1)</span><br><span class="line">    output2 = sigmoid(output1)</span><br><span class="line">    output3 = linear(x, k2, b2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output3</span><br><span class="line"></span><br><span class="line">trying_time = <span class="number">50000</span></span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\sigma (x)=\frac{1}{1+e^{-x}}</script><script type="math/tex; mode=display">loss(y,\hat y)=\frac{1}{n}\sum (y-\hat y)^2</script><script type="math/tex; mode=display">\hat y=k_2\sigma(g)+b_2</script><script type="math/tex; mode=display">g=k_1x+b_1</script><script type="math/tex; mode=display">\frac{\partial loss}{\partial k_1}=\frac{\partial loss}{\partial \hat y}\frac{\partial \hat y}{\partial \sigma}\frac{\partial \sigma}{\partial g}\frac{\partial g}{\partial k_1}</script><ul><li>理论上，线性+非线性的组合可以拟合任意函数</li><li>为什么还要提出如CNN,RNN,Transformer等网络？</li><li>因为拟合函数时，每增加一个参数维度，所需数据量大约须增加10倍</li><li>为了减少需要的数据量，提出了上述特殊的网络，利用权值共享减少参数量，从而减少数据量</li></ul><h1 id="计算图computing-graph"><a href="#计算图computing-graph" class="headerlink" title="计算图computing graph"></a>计算图computing graph</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">computing_graph = &#123;</span><br><span class="line">    <span class="string">'x1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'k1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'b1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'linear-01'</span>:[<span class="string">'sigmoid'</span>],</span><br><span class="line">    <span class="string">'sigmoid'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'k2'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'b2'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'linear-02'</span>:[<span class="string">'loss'</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx <span class="comment"># 画神经网络流程图</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">graph = nx.DiGraph(computing_graph)</span><br><span class="line">layout = nx.layout.spring_layout(graph)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nx.draw(graph, layout, with_labels=<span class="literal">True</span>, node_color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/f49f8133d98e7810a2e2018495372ff6.png" alt=""></p><h1 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visited_procedure</span><span class="params">(graph, position, visited_order, step, sub_plot_index=None, colors=<span class="params">(<span class="string">'red'</span>, <span class="string">'green'</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 将图graph按照访问顺序visited_order变换颜色</span></span><br><span class="line">    changed = visited_order[:step] <span class="keyword">if</span> step <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> visited_order <span class="comment"># 用step设置被访问的节点</span></span><br><span class="line">    </span><br><span class="line">    before, after = colors <span class="comment"># before代表未被访问的节点颜色，after代表已被访问的节点颜色</span></span><br><span class="line">    </span><br><span class="line">    color_map = [after <span class="keyword">if</span> c <span class="keyword">in</span> changed <span class="keyword">else</span> before <span class="keyword">for</span> c <span class="keyword">in</span> graph] <span class="comment"># 若节点c属于被访问的节点，则颜色设置为after;否则颜色设置为before</span></span><br><span class="line">    </span><br><span class="line">    nx.draw(graph, position, node_color=color_map, with_labels=<span class="literal">True</span>,ax=sub_plot_index) <span class="comment"># 画图，ax=sub_plot_index设置该幅图所在子图的索引</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visited_order = [<span class="string">'x1'</span>,<span class="string">'b1'</span>,<span class="string">'k1'</span>,<span class="string">'linear-01'</span>,<span class="string">'sigmoid'</span>,<span class="string">'b2'</span>,<span class="string">'k2'</span>,<span class="string">'linear-02'</span>,<span class="string">'loss'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visited_procedure(graph, layout, visited_order, step = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/8e90b1bb66857ac3b987784e22b48894.png" alt="output_39_0"></p><h2 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(visited_order)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(visited_order)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    print(ix)</span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, visited_order, step=i, sub_plot_index=ax[ix])</span><br></pre></td></tr></table></figure><pre><code>(0, 0)(0, 1)(0, 2)(0, 3)(1, 0)(1, 1)(1, 2)(1, 3)(2, 0)(2, 1)</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/ea5d08641ff04992745995ab966cb296.png" alt="output_41_1"></p><h2 id="Backward-Propagation"><a href="#Backward-Propagation" class="headerlink" title="Backward Propagation"></a>Backward Propagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(visited_order)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(visited_order)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, visited_order[::<span class="number">-1</span>], step=i, sub_plot_index=ax[ix], colors=(<span class="string">'green'</span>,<span class="string">'red'</span>))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/5bf9fad724fbcccd68410ca084ffe23a.png" alt="output_43_0"></p><h2 id="拓扑算法"><a href="#拓扑算法" class="headerlink" title="拓扑算法"></a>拓扑算法</h2><ol><li>找到一个只有输出，没有输入的节点（若有多个就随机选择其中一个）</li><li>删除并记录该节点</li><li>把该节点的输出连接删除</li><li>重复上述步骤，直到将所有节点全部删除</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toplogic</span><span class="params">(graph)</span>:</span> <span class="comment"># 拓扑排序函数，返回根据graph而得到的节点顺序列表</span></span><br><span class="line">    sorted_node = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(graph) &gt; <span class="number">0</span>:</span><br><span class="line">        all_inputs = []</span><br><span class="line">        all_outputs = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> graph:</span><br><span class="line">            all_inputs += graph[n] <span class="comment"># 收集所有有输入的节点</span></span><br><span class="line">            all_outputs.append(n) <span class="comment"># 收集所有有输出的节点</span></span><br><span class="line">            </span><br><span class="line">        all_inputs = set(all_inputs)</span><br><span class="line">        all_outputs = set(all_outputs)</span><br><span class="line">        <span class="comment">#print(all_inputs)</span></span><br><span class="line">        <span class="comment">#print(all_outputs)</span></span><br><span class="line">        need_remove = all_outputs - all_inputs </span><br><span class="line">        <span class="comment">#print(need_remove)</span></span><br><span class="line">        <span class="keyword">if</span> len(need_remove) &gt; <span class="number">0</span>:</span><br><span class="line">            node = random.choice(list(need_remove))</span><br><span class="line">            <span class="keyword">if</span> len(graph) == <span class="number">1</span>: temp = graph[node]</span><br><span class="line">            graph.pop(node) <span class="comment"># 删除该节点</span></span><br><span class="line">            sorted_node.append(node)</span><br><span class="line">            <span class="keyword">if</span> len(graph) &lt; <span class="number">1</span>: sorted_node += temp</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> sorted_node</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">computing_graph = &#123; <span class="comment"># 人为设计一种网络结构computing_graph，key-value代表一段网络的输入和输出</span></span><br><span class="line">    <span class="string">'x1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'k1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'b1'</span>:[<span class="string">'linear-01'</span>],</span><br><span class="line">    <span class="string">'linear-01'</span>:[<span class="string">'sigmoid'</span>],</span><br><span class="line">    <span class="string">'sigmoid'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'k2'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'b2'</span>:[<span class="string">'linear-02'</span>],</span><br><span class="line">    <span class="string">'linear-02'</span>:[<span class="string">'loss'</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">visited_order_by_algorithm = toplogic(computing_graph) <span class="comment"># 通过toplogic函数返回computing_graph网络在传播时的先后顺序</span></span><br><span class="line"></span><br><span class="line">dimension = int(len(visited_order_by_algorithm)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(visited_order_by_algorithm)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, visited_order_by_algorithm, step=i, sub_plot_index=ax[ix])</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/432bb1ed720dd7c4745d2a2130cec21c.png" alt="output_47_0"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(visited_order_by_algorithm)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(visited_order_by_algorithm)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, visited_order_by_algorithm[::<span class="number">-1</span>], step=i, sub_plot_index=ax[ix], colors=(<span class="string">'green'</span>,<span class="string">'red'</span>))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/20050fc88eea927c46099725ce72370e.png" alt="output_48_0"></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> Backward Propagation </tag>
            
            <tag> 拓扑排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习框架搭建课程一（线性回归与梯度下降）</title>
      <link href="/2020/08/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%80%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%89/"/>
      <url>/2020/08/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%80%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<ul><li>回归(Regression)-&gt;拟合、预测</li><li>分类(Classification)-&gt;输出类别</li></ul><h2 id="根据卧室面积预测房价"><a href="#根据卧室面积预测房价" class="headerlink" title="根据卧室面积预测房价"></a>根据卧室面积预测房价</h2><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston <span class="comment"># 从sklearn库中调用波士顿房价数据</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = load_boston()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X, y = data[<span class="string">'data'</span>], data[<span class="string">'target'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_rm = X[:, <span class="number">5</span>] <span class="comment"># 取出X中房间面积的数据</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_rm, y)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7fc0122d41d0&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/cfdeaa2eba6c0d289ed1b81f3cd0a003.png" alt=""></p><h2 id="本课为线性回归，故需找出一条最佳的直线-y-wx-b-，来拟合卧室和房价的关系"><a href="#本课为线性回归，故需找出一条最佳的直线-y-wx-b-，来拟合卧室和房价的关系" class="headerlink" title="本课为线性回归，故需找出一条最佳的直线$y=wx+b$，来拟合卧室和房价的关系"></a>本课为线性回归，故需找出一条最佳的直线$y=wx+b$，来拟合卧室和房价的关系</h2><h3 id="第一种方法：随机找，记录最优值。"><a href="#第一种方法：随机找，记录最优值。" class="headerlink" title="第一种方法：随机找，记录最优值。"></a>第一种方法：随机找，记录最优值。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> random.randint(<span class="number">-50</span>,<span class="number">50</span>) * x + random.randint(<span class="number">-50</span>,<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X_rm, y)</span><br><span class="line">plt.plot(X_rm, f(X_rm), color = <span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fc010fe5090&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/70a629eb6d9968bbe6fe732622265163.png" alt="output_12_1"></p><p><strong>判断拟合结果好与不好的标准(Evaluation)</strong></p><ul><li>存在一组$x$，假设一个函数$f(x)$，输出估计的$\hat y$，衡量输出结果的好坏在于衡量真实$y$与估计$\hat y$之间的差距。</li></ul><script type="math/tex; mode=display">L1\_loss=\frac {1}{n}\sum_{i=1}^n|y_{true_i}-\hat y_i|</script><script type="math/tex; mode=display">L2\_loss=\frac {1}{n}\sum_{i=1}^n(y_{true_i}-\hat y_i)^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2_loss</span><span class="params">(y,yhat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.mean((np.array(y) - np.array(yhat)) ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">price</span><span class="params">(x, k, b)</span>:</span> <span class="comment"># 线性拟合模型</span></span><br><span class="line">    <span class="keyword">return</span> k * x + b</span><br><span class="line"></span><br><span class="line">trying_time = <span class="number">1000</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">best_k, best_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">loss_update = []</span><br><span class="line"><span class="comment">#######################随机找拟合模型，记录最优情况#######################</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(trying_time):</span><br><span class="line">    k = random.randint(<span class="number">-200</span>,<span class="number">200</span>)</span><br><span class="line">    b = random.randint(<span class="number">-200</span>,<span class="number">200</span>)</span><br><span class="line">    </span><br><span class="line">    yhat = price(X_rm, k, b)</span><br><span class="line">    </span><br><span class="line">    L2 = l2_loss(y=y, yhat=yhat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> L2 &lt; min_loss:</span><br><span class="line">        min_loss = L2</span><br><span class="line">        best_k, best_b = k, b</span><br><span class="line">        loss_update.append([i, L2])</span><br><span class="line">        print(<span class="string">"在第&#123;&#125;步时，k和b更好，此时的Loss是：&#123;&#125;"</span>.format(i, L2))</span><br><span class="line">        </span><br><span class="line">plt.scatter(X_rm, y)</span><br><span class="line">plt.plot(X_rm, price(X_rm, best_k, best_b), color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><pre><code>在第0步时，k和b更好，此时的Loss是：250189.90831387945在第2步时，k和b更好，此时的Loss是：31492.41583403755在第5步时，k和b更好，此时的Loss是：85.14510595256915[&lt;matplotlib.lines.Line2D at 0x7fc010f60f10&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/fa3d4829ab099075c9645fb01b9ce957.png" alt="output_17_2"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_i, loss_y = [i <span class="keyword">for</span> i, l_ <span class="keyword">in</span> loss_update], [l_ <span class="keyword">for</span> i, l_ <span class="keyword">in</span> loss_update]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_i, loss_y)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fc010e8db90&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/fe704e3344bb5862ca1f6c815e69e3e0.png" alt="output_19_1"></p><h2 id="如何让Loss更快地下降？"><a href="#如何让Loss更快地下降？" class="headerlink" title="如何让Loss更快地下降？"></a><strong>如何让Loss更快地下降？</strong></h2><p>梯度方向是函数增长最快的方向，则负梯度方向是函数下降最快的方向。通过计算函数梯度，在负梯度方向更新自变量的值，就能逐渐减小Loss值。——梯度下降法</p><script type="math/tex; mode=display">L2\_loss=\frac{1}{n}\sum_{i=1}^n(y_{true_i}-\hat y_i)^2</script><script type="math/tex; mode=display">=\frac{1}{n}\sum_{i=1}^n(y_{true_i}-(k\times x_i+b))^2</script><script type="math/tex; mode=display">\frac{\partial loss}{\partial k}=-\frac{2}{n}\sum (y_{true_i}-(k\times x_i+b))x_i</script><script type="math/tex; mode=display">=-\frac{2}{n}\sum (y_{true_i}-\hat y_i)x_i</script><script type="math/tex; mode=display">\frac{\partial loss}{\partial b}=-\frac{2}{n}\sum (y_{true_i}-\hat y_i)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partial_k</span><span class="params">(y, yhat, x)</span>:</span> <span class="comment"># loss对k的偏导</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span> * np.mean((np.array(y)-np.array(yhat)) * np.array(x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partial_b</span><span class="params">(y, yhat)</span>:</span> <span class="comment"># loss对b的偏导</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span> * np.mean((np.array(y)-np.array(yhat)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">trying_time = <span class="number">1000</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">best_k, best_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">loss_update = []</span><br><span class="line"></span><br><span class="line">k = random.randint(<span class="number">-200</span>,<span class="number">200</span>)</span><br><span class="line">b = random.randint(<span class="number">-200</span>,<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"><span class="comment">#############################梯度下降法求拟合模型#######################</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(trying_time):</span><br><span class="line">    yhat = price(X_rm, k, b)</span><br><span class="line">    L2 = l2_loss(y, yhat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> L2 &lt; min_loss:</span><br><span class="line">        min_loss = L2</span><br><span class="line">        best_k, best_b = k, b</span><br><span class="line">        loss_update.append([i, L2])</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"在第&#123;&#125;步时，k和b更好，此时的Loss是：&#123;&#125;"</span>.format(i, L2))</span><br><span class="line">        </span><br><span class="line">    gradient_k = partial_k(y, yhat, X_rm)</span><br><span class="line">    gradient_b = partial_b(y, yhat)</span><br><span class="line">    </span><br><span class="line">    k = k - gradient_k * learning_rate</span><br><span class="line">    b = b - gradient_b * learning_rate</span><br><span class="line">    </span><br><span class="line">plt.scatter(X_rm, y)</span><br><span class="line">plt.plot(X_rm, price(X_rm, best_k, best_b),color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><pre><code>在第0步时，k和b更好，此时的Loss是：683883.8072032174在第100步时，k和b更好，此时的Loss是：43.75703967614612在第200步时，k和b更好，此时的Loss是：43.73083829219306在第300步时，k和b更好，此时的Loss是：43.730213182251454在第400步时，k和b更好，此时的Loss是：43.72959107251158在第500步时，k和b更好，此时的Loss是：43.728971947626825在第600步时，k和b更好，此时的Loss是：43.728355793276016在第700步时，k和b更好，此时的Loss是：43.72774259520664在第800步时，k和b更好，此时的Loss是：43.72713233923459在第900步时，k和b更好，此时的Loss是：43.72652501124383[&lt;matplotlib.lines.Line2D at 0x7fc010f57e50&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/c2b5fb4350db8a5027c1888e8e4b6a49.png" alt="output_24_2"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_i, x_l = [i <span class="keyword">for</span> i, l <span class="keyword">in</span> loss_update], [l <span class="keyword">for</span> i, l <span class="keyword">in</span> loss_update]</span><br><span class="line">plt.plot(x_i, x_l)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fc010d87c10&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/789498565a8534739b250ed87a024518.png" alt="output_25_1"></p><p><strong>选择L1_loss作为评价标准时</strong></p><script type="math/tex; mode=display">L1\_loss=\frac{1}{n}\sum_{i=1}^n|y_{true_i}-\hat y_i|</script><script type="math/tex; mode=display">=\frac{1}{n}\sum_{i=1}^n|y_{true_i}-(k\times x_i+b)|</script><script type="math/tex; mode=display">\frac{\partial loss}{\partial k}=-\frac{1}{n}\sum_{i}^n x_i+\frac{1}{n}\sum_j^n x_j,y_{true_i}-\hat y_i>0, y_{true_j}-\hat y_j<0</script><script type="math/tex; mode=display">\frac{\partial loss}{\partial b}=-\frac{1}{n}\sum_{i}^n 1+\frac{1}{n}\sum_j^n 1,y_{true_i}-\hat y_i>0, y_{true_j}-\hat y_j<0</script><h2 id="选用L1-loss时的梯度下降过程"><a href="#选用L1-loss时的梯度下降过程" class="headerlink" title="选用L1_loss时的梯度下降过程"></a>选用L1_loss时的梯度下降过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l1_partial_k</span><span class="params">(x, y, yhat)</span>:</span></span><br><span class="line">    out = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">        <span class="keyword">if</span> y[i] &gt; yhat[i]: </span><br><span class="line">            out.append(-x[i])</span><br><span class="line">        <span class="keyword">elif</span> abs(y[i] - yhat[i])&lt;<span class="number">1e-5</span>:</span><br><span class="line">            out.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out.append(x[i])</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> np.mean(np.array(out))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l1_partial_b</span><span class="params">(x, y, yhat)</span>:</span></span><br><span class="line">    out = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x)):</span><br><span class="line">        <span class="keyword">if</span> y[i] &gt;= yhat[i]:</span><br><span class="line">            out.append(<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">elif</span> abs(y[i] - yhat[i])&lt;<span class="number">1e-5</span>:</span><br><span class="line">            out.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            out.append(<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> np.mean(np.array(out))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l1_loss</span><span class="params">(y, yhat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(abs(np.array(y)-np.array(yhat)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">trying_time = <span class="number">10000</span></span><br><span class="line">min_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">best_k, best_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">loss_update = []</span><br><span class="line"></span><br><span class="line">k = random.randint(<span class="number">-100</span>,<span class="number">100</span>)</span><br><span class="line">b = random.randint(<span class="number">-100</span>,<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"><span class="comment">###################L1_loss下的梯度下降过程##################</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(trying_time):</span><br><span class="line">    yhat = price(X_rm, k, b)</span><br><span class="line">    L1 = l1_loss(y, yhat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> L1 &lt; min_loss:</span><br><span class="line">        min_loss = L1</span><br><span class="line">        best_k, best_b = k, b</span><br><span class="line">        loss_update.append([i, L1])</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"在第&#123;&#125;步时，k和b更好，此时的Loss是：&#123;&#125;"</span>.format(i, L1))</span><br><span class="line">        </span><br><span class="line">    gradient_k = l1_partial_k(X_rm, y, yhat)</span><br><span class="line">    gradient_b = l1_partial_b(X_rm, y, yhat)</span><br><span class="line">    </span><br><span class="line">    k = k - gradient_k * learning_rate</span><br><span class="line">    b = b - gradient_b * learning_rate</span><br><span class="line">    </span><br><span class="line">plt.scatter(X_rm, y)</span><br><span class="line">plt.plot(X_rm, price(X_rm, best_k, best_b),color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><pre><code>在第0步时，k和b更好，此时的Loss是：514.2228260869565在第100步时，k和b更好，此时的Loss是：510.17316314868566在第200步时，k和b更好，此时的Loss是：506.1235002104149在第300步时，k和b更好，此时的Loss是：502.07383727214403在第400步时，k和b更好，此时的Loss是：498.0241743338732在第500步时，k和b更好，此时的Loss是：493.9745113956023在第600步时，k和b更好，此时的Loss是：489.92484845733156在第700步时，k和b更好，此时的Loss是：485.8751855190608在第800步时，k和b更好，此时的Loss是：481.8255225807899在第900步时，k和b更好，此时的Loss是：477.77585964251904在第1000步时，k和b更好，此时的Loss是：473.72619670424825在第1100步时，k和b更好，此时的Loss是：469.67653376597747在第1200步时，k和b更好，此时的Loss是：465.62687082770657在第1300步时，k和b更好，此时的Loss是：461.5772078894358在第1400步时，k和b更好，此时的Loss是：457.52754495116494在第1500步时，k和b更好，此时的Loss是：453.4778820128941在第1600步时，k和b更好，此时的Loss是：449.4282190746233在第1700步时，k和b更好，此时的Loss是：445.3785561363524在第1800步时，k和b更好，此时的Loss是：441.32889319808163在第1900步时，k和b更好，此时的Loss是：437.27923025981084在第2000步时，k和b更好，此时的Loss是：433.22956732154在第2100步时，k和b更好，此时的Loss是：429.17990438326916在第2200步时，k和b更好，此时的Loss是：425.13024144499826在第2300步时，k和b更好，此时的Loss是：421.0805785067275在第2400步时，k和b更好，此时的Loss是：417.0309155684567在第2500步时，k和b更好，此时的Loss是：412.98125263018585在第2600步时，k和b更好，此时的Loss是：408.931589691915在第2700步时，k和b更好，此时的Loss是：404.8819267536443在第2800步时，k和b更好，此时的Loss是：400.8322638153734在第2900步时，k和b更好，此时的Loss是：396.78260087710254在第3000步时，k和b更好，此时的Loss是：392.7329379388317在第3100步时，k和b更好，此时的Loss是：388.6832750005609在第3200步时，k和b更好，此时的Loss是：384.63361206229007在第3300步时，k和b更好，此时的Loss是：380.5839491240192在第3400步时，k和b更好，此时的Loss是：376.53428618574844在第3500步时，k和b更好，此时的Loss是：372.48462324747754在第3600步时，k和b更好，此时的Loss是：368.4349603092068在第3700步时，k和b更好，此时的Loss是：364.3852973709359在第3800步时，k和b更好，此时的Loss是：360.3356344326651在第3900步时，k和b更好，此时的Loss是：356.2859714943943在第4000步时，k和b更好，此时的Loss是：352.23630855612345在第4100步时，k和b更好，此时的Loss是：348.18664561785266在第4200步时，k和b更好，此时的Loss是：344.13698267958176在第4300步时，k和b更好，此时的Loss是：340.087319741311在第4400步时，k和b更好，此时的Loss是：336.0376568030401在第4500步时，k和b更好，此时的Loss是：331.98799386476935在第4600步时，k和b更好，此时的Loss是：327.93833092649857在第4700步时，k和b更好，此时的Loss是：323.8886679882277在第4800步时，k和b更好，此时的Loss是：319.839005049958在第4900步时，k和b更好，此时的Loss是：315.7893421116916在第5000步时，k和b更好，此时的Loss是：311.7396791734253在第5100步时，k和b更好，此时的Loss是：307.69001623515896在第5200步时，k和b更好，此时的Loss是：303.6403532968926在第5300步时，k和b更好，此时的Loss是：299.5906903586262在第5400步时，k和b更好，此时的Loss是：295.54102742035985在第5500步时，k和b更好，此时的Loss是：291.4913644820935在第5600步时，k和b更好，此时的Loss是：287.4417015438272在第5700步时，k和b更好，此时的Loss是：283.3920386055608在第5800步时，k和b更好，此时的Loss是：279.34237566729445在第5900步时，k和b更好，此时的Loss是：275.29271272902804在第6000步时，k和b更好，此时的Loss是：271.24304979076175在第6100步时，k和b更好，此时的Loss是：267.19338685249534在第6200步时，k和b更好，此时的Loss是：263.143723914229在第6300步时，k和b更好，此时的Loss是：259.09406097596263在第6400步时，k和b更好，此时的Loss是：255.04439803769628在第6500步时，k和b更好，此时的Loss是：250.99473509942993在第6600步时，k和b更好，此时的Loss是：246.94507216116358在第6700步时，k和b更好，此时的Loss是：242.89540922289717在第6800步时，k和b更好，此时的Loss是：238.84574628463085在第6900步时，k和b更好，此时的Loss是：234.79608334636447在第7000步时，k和b更好，此时的Loss是：230.7464204080981在第7100步时，k和b更好，此时的Loss是：226.69675746983174在第7200步时，k和b更好，此时的Loss是：222.6470945315654在第7300步时，k和b更好，此时的Loss是：218.597431593299在第7400步时，k和b更好，此时的Loss是：214.54776865503268在第7500步时，k和b更好，此时的Loss是：210.4981057167663在第7600步时，k和b更好，此时的Loss是：206.44844277849992在第7700步时，k和b更好，此时的Loss是：202.3987798402336在第7800步时，k和b更好，此时的Loss是：198.34911690196722在第7900步时，k和b更好，此时的Loss是：194.29945396370084在第8000步时，k和b更好，此时的Loss是：190.2497910254345在第8100步时，k和b更好，此时的Loss是：186.20012808716814在第8200步时，k和b更好，此时的Loss是：182.15046514890176在第8300步时，k和b更好，此时的Loss是：178.1008022106354在第8400步时，k和b更好，此时的Loss是：174.05113927236906在第8500步时，k和b更好，此时的Loss是：170.0014763341027在第8600步时，k和b更好，此时的Loss是：165.95181339583633在第8700步时，k和b更好，此时的Loss是：161.90215045756997在第8800步时，k和b更好，此时的Loss是：157.85248751930362在第8900步时，k和b更好，此时的Loss是：153.80282458103724在第9000步时，k和b更好，此时的Loss是：149.7531616427709在第9100步时，k和b更好，此时的Loss是：145.70349870450454在第9200步时，k和b更好，此时的Loss是：141.6538357662382在第9300步时，k和b更好，此时的Loss是：137.6041728279718在第9400步时，k和b更好，此时的Loss是：133.55450988970543在第9500步时，k和b更好，此时的Loss是：129.50484695143908在第9600步时，k和b更好，此时的Loss是：125.45518401317273在第9700步时，k和b更好，此时的Loss是：121.40552107490637在第9800步时，k和b更好，此时的Loss是：117.35585813664001在第9900步时，k和b更好，此时的Loss是：113.30619519837286[&lt;matplotlib.lines.Line2D at 0x7fc010f27490&gt;]</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/98eee24a6c9ca30e799063656f67c3b4.png" alt="output_29_2"></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DL </tag>
            
            <tag> Gradient Descent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv1(You Only Look Once)</title>
      <link href="/2020/07/13/YOLOv1(You-Only-Look-Once)/"/>
      <url>/2020/07/13/YOLOv1(You-Only-Look-Once)/</url>
      
        <content type="html"><![CDATA[<h1 id="REFENRECE"><a href="#REFENRECE" class="headerlink" title="REFENRECE"></a>REFENRECE</h1><p>1.<a href="https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247494712&amp;idx=3&amp;sn=fe711048161e9c4d11b95e887fe041a0&amp;chksm=ec1c01c1db6b88d7c25a6a812acdf94e944542a1db9abe6c42bf3f5e202abe02f6b562c1a719&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&amp;mid=2247494712&amp;idx=3&amp;sn=fe711048161e9c4d11b95e887fe041a0&amp;chksm=ec1c01c1db6b88d7c25a6a812acdf94e944542a1db9abe6c42bf3f5e202abe02f6b562c1a719&amp;scene=21#wechat_redirect</a></p><p>2.<a href="https://www.jianshu.com/p/cad68ca85e27" target="_blank" rel="noopener">https://www.jianshu.com/p/cad68ca85e27</a></p><p>3.<a href="https://blog.csdn.net/u014380165/article/details/72616238?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/72616238?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4</a></p><h1 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h1><p>　　faster-RCNN之后，rbg(RossGirshick)提出的另一种目标检测框架YOLO。</p><p>　　论文下载：<a href="http://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">http://arxiv.org/abs/1506.02640</a></p><p>　　代码下载：<a href="http://github.com/pjreddie/darknet" target="_blank" rel="noopener">http://github.com/pjreddie/darknet</a></p><h2 id="1-YOLO的核心思想"><a href="#1-YOLO的核心思想" class="headerlink" title="1.YOLO的核心思想"></a>1.YOLO的核心思想</h2><p>　　利用整张图作为网络输入，直接在输出层回归bbox的位置和所属类别。YOLOv1在速度上有大幅提升，处理速度可达到45fps，其快速版本（网络较小）甚至可以达到155fps。</p><h2 id="2-YOLO的实现方法"><a href="#2-YOLO的实现方法" class="headerlink" title="2.YOLO的实现方法"></a>2.YOLO的实现方法</h2><p>　　将一幅图像分成$S\times S$个网格，若某个object中心落在这个网格中，则这个网格就负责预测这个object。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/11/5a713128a524820e79255f09926b5209.png" alt=""></p><p>　　每个网格要预测2个bbox，每个bbox除了要回归自身坐标外，还要附带预测一个confidence值。每个bbox要预测(x,y,w,h)和confidence共5个值，每个网格要预测类别信息，记为C。每个网格还要预测2个bbox。则整幅图的输出就是$S\times S\times (2\times 5+C)$。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/ad14e3f255a002e8a6bcdbcc136321a8.png" style="zoom:80%;" /></p><ol><li><p>C指的是类别数，每个输出tensor里有C个位置记录该网格存在某一种目标的概率，可记为</p><p>　　　　　　　　　　　　<script type="math/tex">P(C_{1}|Object),\cdots ,P(C_{i}|Object),\cdots</script></p><p>理解成条件概率（当网格存在object时，该object是$C_{i}$类的概率）。</p></li><li><p>每个bbox需要4个数值来表示位置，(Center_x,Center_y,width,height)。</p></li><li><p>bbox的置信度confidence</p><p>　　　　　　　　　　　　$confidence=Pr(Object)\times IOU_{pred}^{truth}$</p><p>这个confidence代表所预测的bbox中含有object的概率和该box预测有多准两重信息。其中若有object落在一个网格中，则$Pr(Object)=1$，否则取0；第二项指预测的bbox和实际groundtruth之间的IoU值。</p></li></ol><h2 id="3-讨论"><a href="#3-讨论" class="headerlink" title="3.讨论"></a>3.讨论</h2><ol><li><p>类别信息是针对每个网格的，confidence是针对每个bbox的。</p></li><li><p>　　YOLOv1的bbox并不是faster RCNN的Anchor。faster RCNN采用手工设置好的anchor，每个anchor有不同的大小和宽高比。YOLOv1并没有预先设置bbox的大小和形状，这里的bbox更像是进化算法，即事先并不知道会在什么位置，需经过前向计算，网络输出2个bbox。训练开始阶段，网络预测的bbox可能都是乱来的，但总是选择IoU相对大一些的那个bbox继续训练，每个bbox会逐渐擅长对某些情况的预测。</p></li><li><p>训练样本构造</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/f54950a926674fc20e4b650e39bb79b2.png" style="zoom:67%;" /></p><p><strong>①</strong>　　对于输入图像中的每个对象，先找到中心点，如上图中的自行车，中心点在黄色圆点位置，则该黄色网格对应的标签中，自行车的概率设为1，其他对象的概率设为0。所有其他48个网格的标签中，该自行车的概率都设为0。（这就是中心点所在的网格对预测该对象负责）</p><p><strong>②</strong>　　每个网格的输出包含2个bbox，每个bbox又包含一个confidence值。比较2个bbox的IoU，IoU大的那个bbox的$Pr(Object)=1$，同时真实bbox的值也就填入标签对应的bbox。另一个不负责预测的bbox的$Pr(Object)=0$。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/fab11a59ae9f6579517b7d631d951acf.png" style="zoom:50%;" /></p><p><strong>注</strong>：上图将自行车的真实位置放在bbox1，但实际是在训练过程中等网络输出以后，比较两个bbox与自行车真实位置的IoU，自行车的真实位置放在IoU比较大的那个bbox中，且将该bbox的confidence置为1。</p></li><li><p>损失函数</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/fbac459f013bd6d6085e3de8d7738553.png" style="zoom:50%;" /></p><p>损失函数如下：</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/529cf3f362320cb27b228e1062fb1d81.png" style="zoom: 80%;" /></p><p><strong>①</strong>目标分类的误差：公式第5行表示存在object的网格才计入误差。</p><p><strong>②</strong>bbox的位置误差：公式第1行和第2行</p><ol><li><p>都有系数$1_{ij}^{obj}$表示只有负责(IoU比较大)预测的那个bbox计入误差。</p></li><li><p>第2行公式中宽和高都先取了平方根，这样做是因为相同的宽和高的误差对于小目标精度影响比大目标要大。比如，原始w=10,h=20，预测w=8,h=22和原始w=3,h=5，预测w=1,h=7相比，其实前者误差比后者小，但如果不开平方根，则损失是相等的：4+4=8，而取平方根后，变成0.15和0.7。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/07/12/8e0f4b6e33129fec4c1fd2e9af602302.png" alt=""></p><p>由上图知，取平方根后，小box的在横轴上的值较小，发生偏移时，反应到y轴上的偏差比大box要大。</p></li></ol><p><strong>③</strong>bbox的confidence误差：</p><ol><li>公式第三行是存在object的bbox的confidence误差。系数$1_{ij}^{obj}$表示只有负责(IoU比较大)预测的那个bbox的confidence才会计入这项误差。</li><li>公式第四行是不存在object的bbox的confidence误差。若该项不恰当地输出较高的confidence，则会与真正负责该object预测的那个bbox混淆。</li></ol><p><strong>④</strong>几个问题</p><ol><li>8维的localization error和20维的classification error同等重要是不合理的。</li><li>若一个网格中没有object（一幅图中这种网格很多），那么就会将这些网格中的bbox的confidence push到0，相比于较少的有object的网格，这种做法会导致网络不稳定甚至发散。</li></ol><p><strong>⑤</strong>解决办法</p><ul><li>更重视8维的坐标预测，给这些损失前面赋予更大的权重$λ_{coord}$，在pascal VOC训练中取5。</li><li>对没有object的bbox的confidence loss，赋予较小的权重$λ_{noobj}$，在pascal VOC训练中取0.5。</li><li>有object的bbox的confidence loss和类别的loss的权重取1。</li></ul></li><li><p>　　在test的时候，每个网格预测的class信息和bbox预测的confidence信息相乘，就得到每个bbox的class-specific confidence score：</p><p>　　　　　　　　　　 　<script type="math/tex">Pr(Class_{i}|Object)\times Pr(Object)\times IOU_{pred}^{truth}=Pr(Class_{i})\times IOU_{pred}^{truth}</script></p><p>　　等式左边第一项是每个网格预测的类别信息，后两项是每个bbox的confidence。该乘积即encode了预测的box属于某一类的概率，也包含该box准确度的信息。</p><p>　　得到每个box的class-specific conficence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，得到最终的检测结果。</p></li><li><p>NMS（非极大值抑制）</p><p>　　核心思想：选择得分最高的作为输出，与该输出重叠的去掉，不断重复该过程直到所有备选处理完。</p><p>   　　<strong>具体算法</strong>：设网络输出$7\times 7\times 30$的tensor，在每个网格中，对象$C_{i}$位于第j个bbox的得分为：</p><p>   　　　　　　　　　　　　　　　　<script type="math/tex">score_{ij}=P(C_{i}|Object)\times Confidence_{j}</script></p><p>代表某类对象$C_{i}$存在于第j个bbox的可能性。</p><p>　　每个网格有20个对象(pascal VOC有20类)的概率$\times$2个bbox的confidence，共40个得分。则$7\times 7$个网格共有1960个得分。对每种对象进行NMS，每种对象有1960/20=98个得分。</p><ol><li>设置一个score的阈值，低于该阈值的候选得分排除掉（将score设为0）</li><li>遍历每个对象类别<ol><li>遍历当前对象的98个得分</li><li>找到score最大的那个bbox，添加到输出列表</li><li>对每个score不为0的候选对象，计算其与上面输出对象的bbox的IoU</li><li>根据预先设置的IoU阈值，所有高于该阈值（重叠度较高）的候选对象排除掉（将score设为0）</li><li>如果所有bbox要么在输出列表中，要么score=0，则该对象类别的NMS完成，返回步骤b处理下一种对象</li></ol></li><li>输出列表即为预测的对象</li></ol></li><li><p>激活函数使用leak RELU。</p></li><li><p>　　输出层为全连接层，因此在检测时，模型只支持与训练图像相同的输入分辨率。（因为全连接层神经元固定，接受的输入大小也就固定。而卷积网络因为使用卷积核处理数据，无论输入大小如何，卷积核可始终保持不变。）</p></li><li><p><strong>缺点</strong></p><ol><li>YOLOv1对相互靠得很近的物体，以及很小的物体检测效果不好，因为一个网格只预测了两个框，且都指向一类物体。此外，Pooling层会丢失一些信息，对定位存在影响。</li><li>同一类物体出现的新的不常见的长宽比和其他情况时，泛化能力较弱。</li><li>由于损失函数的问题，定位误差是影响检测效果的主要原因。尤其是大小物体的处理上，还有待加强。</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> object detection </category>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> object detection </tag>
            
            <tag> YOLOv1 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何阅读期刊论文</title>
      <link href="/2020/06/12/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E6%9C%9F%E5%88%8A%E8%AE%BA%E6%96%87/"/>
      <url>/2020/06/12/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E6%9C%9F%E5%88%8A%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<p>​         技术的创新并不是全靠聪明。只要<strong>学会分析期刊论文的优缺点</strong>，就可拿这套方法分析竞争对手产品的优缺点；而且，只要再稍微加工，就可以从这套优缺点的清单里找到突破瓶颈所需的关键性创意。这套创新程序，可以把「创新」变成不需要太多天分便可以完成的事，从而减轻创意的不定性与风险性。因此，只要会分析论文，几乎就可以轻易地组合出你所需要的绝大部分创意。聪明是不可能教的，但这套技巧却是可以教的；而且只要用心，绝大部分硕士生都可以学会。</p><h1 id="期刊论文的分析技巧与程序"><a href="#期刊论文的分析技巧与程序" class="headerlink" title="期刊论文的分析技巧与程序"></a>期刊论文的分析技巧与程序</h1><p>一篇期刊论文，主要分成四个部分。</p><h2 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1. Abstract"></a>1. Abstract</h2><p>​         涉及这篇论文的主要贡献、方法特色与主要内容。须学会只看Abstract和Introduction就判断出这篇论文的重点和自己的研究是否有直接关联，从而决定要不要把它给读完。</p><h2 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2. Introduction"></a>2. Introduction</h2><p>​         介绍问题的背景和起源，交代前人在这个题目上已经有过的主要贡献，说清楚前人留下来的未解问题，以及在这个背景下这篇论文想解决的问题和它的重要性。</p><p>​         对初学者而言，先收集与课题相关的论文30~40篇，每篇都只读Abstract和Introduction，不读Main Body，只在必要时稍微参考一下文后的Illustrative examples和Conclusions，直到能回答以下三个问题：</p><p>（2A）在该领域内最常被引述的方法有哪些？</p><p>（2B）这些方法可以分成哪些主要派别？</p><p>（2C）每个派别的主要特色（含优点和缺点）是什么？</p><p>​        如何找到这30~40篇论文？有一种期刊论文叫review paper，在keywords中加一个review筛选出这类论文，从相关的数篇review paper开始，从中根据title和Abstract找出和自己研究课题相关的30~40篇论文。</p><p>​         通常反复读过这30~40篇论文的Abstract和Introduction，就可以回答（2A）和（2B）。要回答（2A）和（2B），应先挑那些Introduction写的比较有观念的论文（不要直接读写得像流水账的Introduction）。</p><p>​        假如读过30~40篇论文的Abstract和Introduction后，还是回答不了（2C），就先做以下工作：</p><ul><li>先根据（2A）的答案，把该领域内最常被引述的论文找齐，再把他们根据（2B）的答案分成派别，每个派别按日期先后次序排好。然后，每次只重新读一派的Abstract和Introduction（必要时简略参考内文，但目的只是读懂Introduction内与这派有关的陈述，而不需要真的看懂所有内文），照日期先后读，读的时候只考虑回答一个问题：这一派的创意和主要诉求是什么？这样把每一派的Abstract和Introduction读完，总结出这一派主要的诉求、方法特色和优点。</li><li>其次，重读前面这些论文的Introduction，回答问题：每篇论文对其他派别有什么批评？然后把读到的重点逐一记录到各派别的<strong>缺点</strong>栏内。</li></ul><p>​        通过以上程序，可以掌握到（2A）、（2B）和（2C）的答案。这时应该对该领域内主要方法、文献之间的关系比较熟悉了。此时，可以用这些论文测试看看之前用来搜寻该领域论文的keywords恰不恰当，再用修正过的keywords再搜寻一次论文，把该领域的主要文献补齐，也把原来30~40篇论文中关系较远的论文删除，只保留大概20篇左右确定跟自己关系较近的文献。甚至可以删除几个不想用的派别（要有充分理由），只保留另几个派别（也要有充分理由）。</p><p>​         然后再利用（2C）的答案，再进一步回答一个问题（2D）：<strong>这个领域内大家认为重要的关键问题有哪些？有哪些特性是大家重视的优点？有哪些特性是大家在意的缺点？这些优点与缺点通常在哪些应用场合时会比较被重视？在哪些应用场合时比较不会被重视？</strong>然后就可以整理出该领域主要的应用场合，以及这些应用场合上该注意的事项。</p><p>​         最后，根据（2A）和（2C）的答案，把各派别内的论文整理在同一个档案内，按时间顺序排好，然后依照这些派别与自己研究方向的关系远近，逐一把各派论文的Main Body读完。</p><h2 id="3-Main-Body（simulation-and-experimental-examples"><a href="#3-Main-Body（simulation-and-experimental-examples" class="headerlink" title="3. Main Body（simulation and experimental examples)"></a>3. Main Body（simulation and experimental examples)</h2><p>第一次有系统地读某派别的论文Main Body时，只需要读懂：</p><p>（3A）该论文的主要假设是什么（什么条件下是有效的），并评估下这些假设在现实条件下成立的难度。越难成立的假设，越不好用，参考价值也越低。</p><p>（3B）在这些假设下，这篇论文主要有什么好处。</p><p>（3C）这些好处主要表现在哪些公式的哪些项目的简化上。不需要懂这篇论文详细的推导过程。除了三、五个关键的公式（最后在应用上要使用的公式，可以从这些公式评估出该方法使用上的方便程度或计算效率，以及在非理想情境下这些公式使用起来的可靠度或稳定性），其他公式弄不懂也没事，公式之间的恒等式推导过程可完全略过。假如要看公式，重点应看公式推导过程中引入的假设条件，而不是恒等式的推导。</p><p>​         但是，在开始根据前述问题读论文前，应先把收集的该派别所有论文都拿出来，逐篇粗略浏览过去（不要勉强自己每篇或每行都弄懂，而是轻松读，能懂就懂，不懂就不懂），从中挑出容易读懂的papers，以及经常被引述的论文。然后把这些论文按时间顺序依次读下去。读的时候，记得只回答（3A）、（3B）、（3C）就好，不用读太细致。</p><p>​        这样读完论文后，应该把这一派的主要发展过程、主要假设、主要理论依据及主要成果做一个完整梳理。其次，还要根据（2D）的答案及这一派的主要假设，进一步回答问题：（3D）这一派主要的缺点有哪些。最后，根据（3A）、（3B）、（3C）、（3D）的答案综合整理出：这一派最适合什么时候使用，最不适合什么场合使用。</p><p>​        论文作者常常故意只提成功的实验案例，所以simulation examples and experiments表现好不代表这个方法真的很好。必须回到这个方法的基本假设以及在用该方法时所使用的主要公式（resultant equations)上去，参考（2C）和（2D）的答案，问自己：当某个假设无法成立时，该方法会不会出什么状况？猜测该方法应该会在哪些应用场合表现优异，又会在哪些应用场合出状况？根据猜测再检验一次simulation examples and experiments，看其优点和缺点是否确实在这些examples中被充分检验且充分表现出来。</p><p>==注==：任何时候都不需要弄懂一篇论文所有的恒等式推导过程，不需要把整篇论文细细读完，只需要把确定会用到的部分完全弄懂就好，其他的也只需要了解它主要的idea。</p><p><img src="http://images.cnitblog.com/i/326116/201403/211603473659485.png" alt="img"></p><h1 id="方法与应用场合特性表（有迹可寻的创意产生程序）"><a href="#方法与应用场合特性表（有迹可寻的创意产生程序）" class="headerlink" title="方法与应用场合特性表（有迹可寻的创意产生程序）"></a>方法与应用场合特性表（有迹可寻的创意产生程序）</h1><p>从上图的步骤（4）和（5）获得以下两张表：</p><p><img src="http://images.cnitblog.com/i/326116/201403/211602235683420.png" alt="img"></p><p>​         同样一个方法可能有许多不同的应用场合，而不同应用场合可能会对适用（或最佳）的方法有不同要求。<strong>方法没有好坏，只有相对优缺点；只有当方法的特性与应用场合的特性不合时，才能下结论说这方法「不适用」；而当方法的特性与应用场合的特性吻合时，则下结论说这方法「很适用」。</strong></p><p>==技巧==：上面的方法与问题分析对照表还可以用来把「突破瓶颈所需的创意」简化成一种「有迹可寻」的工作。譬如，假定我们要针对应用甲发展一套适用的方法，首先我们要先从上右表中标定这个应用场合关心哪些问题特性。根据上右表第一个 column，甲应用场合只关心四个特性：特性1、2、3、5。哪个方法最适用呢？看起来是方法一，它除了特性2表现普通之外，其它三个特性的表现都很出色。但是，假如我们对方法一的表现仍不够满意，怎么去改善它？最简单的办法就是从上左表找现成的方法和方法一结合，产生出一个更适用的方法。因为方法一只有在特性2上面表现不够令人满意，所以我们就优先针对在特性2上面表现出色的其它方法加以研究。根据上左表，在特性2上面表现出色的方法有方法二和方法四，所以我们就去研究这两个方法和方法一结合的可能性。或许（随便举例）方法四的创意刚好可以被结合进方法一而改善方法一在特性2上面的表现，那么，我们就可以因此轻易地获得一个方法一的改良，从而突破甲应用场合没有适用方法的瓶颈。</p><p><strong>多半时候只要应用上一段的分析技巧就可以产生足以解决实用问题的创意了。</strong></p><h1 id="论文阅读的补充说明"><a href="#论文阅读的补充说明" class="headerlink" title="论文阅读的补充说明"></a>论文阅读的补充说明</h1><p>不好的习惯：</p><p>（1）老是想逐行读懂，有一行读不懂就受不了。</p><p>（2）不敢发挥自己的想象，读论文像在读教科书，论文没写的就不会，瘫痪在那里；自己猜测或想象时，老怕弄错作者的意思，神经绷紧，脑筋根本动不了。</p><p>==注==：每次读论文都一定要带着问题去读，每次读的时候都只是图回答你要回答的问题。因此，一定是选择性地阅读，一定要逐渐由粗而细地一层一层去了解。一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。</p><p>​        许多论文中没被交代的段落你也已经可以有一些属于你的想象，猜完以后要根据你的猜测在论文里找证据，用以判断你的猜测对不对。猜对了，就用你的猜测（其实是你的推理架构）去吸收作者的资讯与创意；猜错了，论文理会有一些信息告诉你说你错了，而且因为猜错所以你读到对的答案时反而印象更深刻。</p><h1 id="论文报告的要求与技巧"><a href="#论文报告的要求与技巧" class="headerlink" title="论文报告的要求与技巧"></a>论文报告的要求与技巧</h1><p>报告一篇论文（依报告次序排列）：</p><p>　　（1） 投影片第一页必须列出论文的题目、作者、论文出处与年份。</p><p>　　（2） 以下每一页投影片只能讲一个观念，不可以在一张投影片里讲两个观念。</p><p>　　（3） 说明这篇论文所研究的问题的重点，以及这个问题可能和工业界的哪些应用相关。</p><p>　　（4） 清楚交代这篇论文的主要假设，主要公式，与主要应用方式（以及应用上可能的解题流程）。</p><p>　　（5） 说明这篇论文的范例（simulation examples and/or experiments），预测这个方法在不同场合时可能会有的准确度或好用的程度</p><p>　　（6） 你个人的分析、评价与批评，包括：</p><p>（6A）这篇论文最主要的创意是什么？</p><p>（6B）这些创意在应用上有什么好处？</p><p>（6C）这些创意和应用上的好处是在哪些条件下才能成立？</p><p>（6D）这篇论文最主要的缺点或局限是什么？</p><p>（6E）这些缺点或局限在应用上有什么坏处？</p><p>（6F）这些缺点和应用上的坏处是因为哪些因素而引入的？</p><p>（6G）你建议学长学弟什么时候参考这篇论文的哪些部分（点子）？</p><p>　　一般来讲，刚开始报告论文（硕一上学期）时只要做到能把前四项要素说清楚就好了，但是硕一结束后（暑假开始）必须要设法做到六项要素都能触及。硕二下学期开始的时候，必须要做到六项都能说清楚。</p><p>　　注意：读论文和报告论文时，最重要的是它的创意和观念架构，而不是数学上恒等式推导过程的细节（顶多只要抓出关键的 equation 去弩懂以及说明清楚即可）。你报告观念与分析创意，别人容易听懂又觉得有趣；你讲恒等式，大家不耐烦又浪费时间。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://blog.csdn.net/symoriaty/article/details/76578180?utm_medium=distribute.pc_relevant_right.none-task-blog-OPENSEARCH-4&amp;depth_1-utm_source=distribute.pc_relevant_right.none-task-blog-OPENSEARCH-4" target="_blank" rel="noopener">https://blog.csdn.net/symoriaty/article/details/76578180?utm_medium=distribute.pc_relevant_right.none-task-blog-OPENSEARCH-4&amp;depth_1-utm_source=distribute.pc_relevant_right.none-task-blog-OPENSEARCH-4</a></p>]]></content>
      
      
      <categories>
          
          <category> postgraduate </category>
          
      </categories>
      
      
        <tags>
            
            <tag> papers reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测mAP(mean Average Precision)</title>
      <link href="/2020/06/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8BmAP(mean%20Average%20Precision)/"/>
      <url>/2020/06/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8BmAP(mean%20Average%20Precision)/</url>
      
        <content type="html"><![CDATA[<p>​         mAP可译为平均精度均值，是目标检测中模型性能的衡量指标。多个类别的目标检测任务中，每个类别都可以根据recall（召回率）和precision（准确率）绘制一条曲线。AP可看作该曲线下的面积，而mAP就是指在求得每一类AP的基础上再计算其所有类别的平均值。</p><h2 id="1-几个概念"><a href="#1-几个概念" class="headerlink" title="1.几个概念"></a>1.几个概念</h2><ol><li><p>True Positives(TP)：实际为正例且被模型划分为正例的实例数。</p></li><li><p>False Positives(FP)：实际为负例但被模型划分为正例的实例数。</p></li><li><p>True  Negatives(TN)：实际为负例且被模型划分为负例的实例数。</p></li><li><p>False Negatives(FN)：实际为正例但被模型划分为负例的实例数。</p></li><li><p>准确率（Precision）可理解为<strong>查准率</strong>，是指在所有预测为正例的样本中，真正例所占的比例。</p><p>召回率 $(\mathrm{recall})=\frac{TP}{TP+FN}=\mathrm{R}$<br>(查全率)</p></li><li><p>召回率（Recall）可理解为<strong>查全率</strong>，是指在所有正例中被正确预测的比例。</p><p>准确率 $(\text { precision })=\frac{TP}{TP+FP}=\mathrm{P}$<br>$($ 查准率)</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/31e94cef78cf781b3f549e250d1ccb36.png" style="zoom:80%;" /></p></li></ol><h2 id="2-单类别AP"><a href="#2-单类别AP" class="headerlink" title="2.单类别AP"></a>2.单类别AP</h2><p>​        目标检测的预测结果通常包含两部分，即预测框(bounding box)和置信度P。而预测正确需要满足两个条件，①类别正确且置信度(confidence score)大于一定阈值(P_threshold)，②预测框与真实框(ground truth)的IoU大于一定阈值(IoU_threshold)。</p><p><strong>示例</strong></p><p>​         假设用训练好的模型得到所有测试样本的confidence score，每一类的confidence score保存到一个文件中，设共有20个测试样本，每个样本的id、confidence score和ground truth label如下。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/fb7774ce5bf0cb75ee27796c374d09f7.png" style="zoom:80%;" /></p><p>然后对confidence score 排序得到，</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/3572ee3351d6f517d777fabe9c7b35c6.png" style="zoom:80%;" /></p><p>再计算precision和recall。比如想得到top-5的结果，则相当于在设定了置信阈值的情况下，上表中前5个样本被认定为正例，其余均为负例。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/70605dd4b6c9bedfc82f756d391e7d92.png" style="zoom:80%;" /></p><p>则在这个例子中，True Positives就是指id为4和2的样本，因为它们的gt_label为1且同时被预测为正例。False Positives就是指id为13、19、6的样本。而从全表看，gt_label为1的有6个样本，即False Negatives为4个，True Negatives为15-4=11个。</p><p>因此，对于top-5而言，Precision=2/(2+3)=0.4，Recall=2/(2+4)=1/3。</p><p>在实际多类别检测任务中，通常不会只通过top-5来衡量模型的好坏，而是需要知道从top-1到top-N（N是所有测试样本个数）对应的Precision和Recall。易知，随着参与计算的样本增加，Recall会越来越大，Precision则整体呈下降趋势。把Recall作为横坐标，Precision 作为纵坐标，即可得到Precision-Recall曲线。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/6cdc453a2895a81d77f2374012808a7b.png" style="zoom:80%;" /></p><p>在计算AP之前，需要先将平滑化。方法是<strong>取查全率大于等于r时最大的查准率p</strong>。即，$p(r)=\max _{\tilde{r} \geq r} p(\tilde{r})$。</p><p>从而得到平滑后的曲线（下图仅为示意图）。</p><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/06/29/6cd16cdf7078d91282559d9d49a9c4fa.png" style="zoom:80%;" /></p><p>而对于AP的计算有两种方法：</p><ol><li><p>voc2010之前的方法</p><p>AP=(平滑后PR曲线上，Recall分别等于0,0.1,0.2,…,1.0等11处Precision的平均值)</p><p>$A P=\frac{1}{11} \sum_{r \subseteq{0,0.1, . ., 1.0}} p(r)$</p></li><li><p>voc2010以后的方法</p><p>AP=平滑后PR曲线下的面积</p></li></ol><h2 id="3-mAP的计算"><a href="#3-mAP的计算" class="headerlink" title="3.mAP的计算"></a>3.mAP的计算</h2><ol><li><p>voc数据集的mAP</p><p>voc数据集中的mAP计算的是IoU_threshold=0.5时各个类别AP的均值。</p></li><li><p>coco数据集的mAP</p><p>coco认为固定IoU_threshold的取值无法有效衡量对模型性能的影响。</p><p>比如A模型在IoU_threshold=0.5时，mAP=0.4，而B模型在IoU_threshold=0.7时，mAP同样为0.4。根据voc的标准，A、B模型的性能一样，但显然B模型的预测框更准确，性能更好。</p><p>故，coco计算IoU_threshold=0.5,0.55,0.6,…,0.95时的各个mAP。</p></li></ol><h2 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h2><p><a href="https://blog.csdn.net/william_hehe/article/details/80006758" target="_blank" rel="noopener">https://blog.csdn.net/william_hehe/article/details/80006758</a></p><p><a href="https://zhuanlan.zhihu.com/p/56961620" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56961620</a></p>]]></content>
      
      
      <categories>
          
          <category> object detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> object detection </tag>
            
            <tag> mAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/06/04/hello-world/"/>
      <url>/2020/06/04/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
