<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>YOLOv4 | rgwang</title><meta name="description" content="conference  yolov4   Abstract 43.5%AP (65.7% AP50) for the MS COCO dataset at a real-time speed of ∼65 FPS on Tesla V100.   Introduction  contributions: develope an efficient and powerful object detec"><meta name="keywords" content="object detection,YOLOv4"><meta name="author" content="rgwang"><meta name="copyright" content="rgwang"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="YOLOv4"><meta name="twitter:description" content="conference  yolov4   Abstract 43.5%AP (65.7% AP50) for the MS COCO dataset at a real-time speed of ∼65 FPS on Tesla V100.   Introduction  contributions: develope an efficient and powerful object detec"><meta name="twitter:image" content="https://rgwang.github.io/img/ball-ball-shaped-color-earth-269724.jpg"><meta property="og:type" content="article"><meta property="og:title" content="YOLOv4"><meta property="og:url" content="https://rgwang.github.io/2020/09/01/yolo4_paper/"><meta property="og:site_name" content="rgwang"><meta property="og:description" content="conference  yolov4   Abstract 43.5%AP (65.7% AP50) for the MS COCO dataset at a real-time speed of ∼65 FPS on Tesla V100.   Introduction  contributions: develope an efficient and powerful object detec"><meta property="og:image" content="https://rgwang.github.io/img/ball-ball-shaped-color-earth-269724.jpg"><meta property="article:published_time" content="2020-09-01T07:32:18.230Z"><meta property="article:modified_time" content="2020-09-21T03:56:01.970Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://rgwang.github.io/2020/09/01/yolo4_paper/"><link rel="next" title="python基础15(时间复杂度)" href="https://rgwang.github.io/2020/08/17/deepshare_python%E5%9F%BA%E7%A1%8015/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://rgwang.github.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: false  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/1971a47ac42c3aad3425f91b89c64fd4.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">22</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/ball-ball-shaped-color-earth-269724.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">rgwang</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">YOLOv4</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-09-01 15:32:18"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-09-01</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-09-21 11:56:01"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-09-21</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/object-detection/">object detection</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/object-detection/YOLO/">YOLO</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">1.1k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 7 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>conference</p>
<ul>
<li><a href="https://arxiv.org/pdf/2004.10934.pdf" target="_blank" rel="noopener">yolov4</a></li>
</ul>
<ol>
<li><p>Abstract</p>
<p>43.5%AP (65.7% AP50) for the MS COCO dataset at a real-<br>time speed of ∼65 FPS on Tesla V100. </p>
</li>
<li><p>Introduction</p>
<ul>
<li>contributions:<ul>
<li>develope an efficient and powerful object detection<br>model. It makes everyone can use a 1080 Ti or 2080 Ti<br>GPU to train a super fast and accurate object detector.</li>
<li>verify the influence of state-of-the-art Bag-of-<br>Freebies and Bag-of-Specials methods of object detec-<br>tion during the detector training.</li>
<li>modify state-of-the-art methods and make them<br>more effecient and suitable for single GPU training,<br>including CBN [89], PAN [49], SAM [85], etc.</li>
</ul>
</li>
</ul>
</li>
<li><p>Related work</p>
<ul>
<li><p>Object detection models</p>
<ul>
<li><p>A detector is composed of two parts: a backbone which is pre-trained on ImageNet and a head which is used to predict classes and bounding boxes of objects.</p>
</li>
<li><p>As to the head part,it is usually categorized into two kinds, i.e., one-stage object detector and two-stage object detector.</p>
</li>
<li><p>Object detectors developed in recent years often insert some layers between backbone and head, and these layers are usually used to collect feature maps from different stages. We call it the neck of an object detector. </p>
</li>
<li><p>In addition, some researchers put their emphasis on directly building a new backbone (DetNet, DetNAS) or a new whole model (SpineNet, HitDetector ) for object detection.</p>
<p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/09/05/a82c3ebfd0ddb07d6c5e019a9fc85863.png" alt="image-20200905152609774"></p>
<p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/09/05/9441244025ae7f064fd50200c453f9e7.png" alt="image-20200905152541897"></p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li><p>Bag of freebies</p>
<ol>
<li><p>definition: the methods that only change the training strategy or only increase the training cost.</p>
</li>
<li><p>data augmentation:</p>
<ol>
<li><p>pixel-wise adjustments: photometric distortions(brightness,contrast,hue,saturation and noise of an image), geometric distortion(random scaling,cropping,flipping and rotating)</p>
<p>Above methods retain original pixel information in the adjusted area.</p>
</li>
<li><p>simulating object occlusion issues: random erase and CutOut(randomly select the rectangle region in an image and fill in a random or complementary value of zero), MixUp(using two images to multiply and superimpose with different coefficient ratios, and then adjusts the label with these superimposed ratios), CutMix(covering the cropped image to rectangle region of other images and adjusting the label according to the size of the mix area), style transfer GAN(effectively reducing the texture bias learned by CNN)</p>
</li>
<li><p>data imbalance between different classes: hard negative example mining or online hard example mining(<strong>in two-stage object detector</strong>), focal loss(<strong>for one-stage object detector</strong>)</p>
</li>
<li><p>express the relationship of the degree of association between different categories with the one-hot hard representation: label smoothing</p>
</li>
<li><p>bounding box regression</p>
<ol>
<li>traditional: Mean Square Error(MSE),  <strong>but</strong> to directly estimate the coordinate values of each point of the BBox is to treat these points as independent variables, but does not consider the integrity of the object itself.</li>
<li>IoU loss, puts the coverage of predicted BBox area and ground truth BBox area into consideration.</li>
<li>GIoU loss(including the shape and orientation of object), finding the smallest area BBox that can simultaneously cover the predicted BBox and ground truth BBox, and using the BBox as the denominator to replace the denominator in IoU loss.</li>
<li>DIoU loss, additionally considers the distance of the center of an object.</li>
<li>CIoU loss, simultaneously considers the overlapping area, the distance between center points and the aspect ratio.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><p>Bag of specials</p>
<ol>
<li>definition: the methods that only increase the inference cost by a small amount but can significantly improve the accuracy of object detection.</li>
<li>enhance receptive field: SPP, ASPP, RFB. </li>
<li>attention module:<ol>
<li>channel-wise attention: Squeeze-and-Excitation(SE)</li>
<li>point-wise attention: Spatial Attention Module(SAM)</li>
</ol>
</li>
<li>feature integration: FPN, SFAM, ASFF, BiFPN.</li>
<li>good activation function: ReLU(substantially solve the gradient vanish problem which is frequently encounterd in traditional tanh and sigmoid activation function), LReLU, PReLU, ReLU6, Scaled Exponential Linear Unit(SELU), Swish, hard-Swish, Mish.(Swish and Mish are continuously differentiable activation function).</li>
<li>post-processing method: NMS(filtering BBoxes that badly predict the same object, and only retain the candidate BBoxes with higher response), greedy NMS, soft NMS(considering  the problem that the occlusion of an object may cause the degradation of confidence score in greedy NMS with IoU score), DIoU NMS(adding the information of the center point distance to the BBox screening process on the basis of soft NMS).</li>
</ol>
</li>
</ul>
<ol>
<li><p>Methodology</p>
<ul>
<li><p>Selection of architecture</p>
<p>Objective: find the optimal balance among the input network resolution, the convolutional layer number, the parameter number and the number of layer outputs(filters).</p>
<p>Next objective: select additional blocks for <strong>increasing the receptive field</strong> and the best method of parameter aggregation from different backbone levels for different detector levels: FPN,PAN,ASFF,BiFPN.</p>
<p>Detector requires the following:</p>
<ul>
<li>Higher input network size(resolution)-for detecting multiple small-sized objects</li>
<li>More layers-for a higher receptive field to cover the increased size of input network</li>
<li>More parameters-for greater capacity of a model to detect multiple objects of different sizes in a single image</li>
</ul>
<p>The influence of the receptive field with different sizes:</p>
<ul>
<li>up to the object size - allows viewing the entire object</li>
<li>up to network size - allows viewing the context around the object</li>
<li>exceeding the network size - increases the number of connections between the image point and the final activation</li>
</ul>
<p><strong>Finally, the paper(Yolov4) chooses choose CSPDarknet53 backbone, SPP additional module, PANet path-aggregation neck, and YOLOv3(anchor based) head as the architecture of YOLOv4.</strong></p>
</li>
<li><p>Selection of BoF and BoS</p>
<p>a CNN usually uses the following training tricks:</p>
<ul>
<li>Activations: ReLU, leaky-ReLU, parametric-ReLU, ReLU6, SELU, Swish, Mish</li>
<li>Bounding box regression loss: MSE, IoU, GIoU, CIoU, DIoU</li>
<li>Data augmentation: CutOut, MixUp, CutMix</li>
<li>Regularization method: DropOut, DropPath, Spatial DropOut, DropBlock</li>
<li>Normalization of the network activations by their mean and variance: Batch Normalization, Cross-GPU Batch Normalization(CGBN or SyncBN), Filter Response Normalization(FRN), Cross-Iteration Batch Normalization(CBN)</li>
<li>Skip-connections: Residual connections, Weighted residual connections, Multi-input weighted residual connections, Cross stage partial connections(CSP)</li>
</ul>
<p>PReLU and SELU are more difficult to train, and ReLU6 is specifically designed for quantization network.</p>
</li>
<li><p>Additional improvements</p>
<ul>
<li>Introducing a new method of data augmentation Mosaic, and Self-Adversarial Training(SAT)</li>
<li>Selecting optimal hyper-parameters while applying genetic algorithms</li>
<li>Modifying some exsiting methods: modified SAM, modified PAN, and Cross mini-Batch Normalization(CmBN)</li>
</ul>
</li>
<li><p>YOLOv4</p>
<p>consists of:</p>
<ul>
<li>Backbone: CSPDarknet53</li>
<li>Neck: SPP, PAN</li>
<li>Head: YOLOv3</li>
</ul>
<p>BoF for backbone: CutMix, Mosaic data augmentation, Dropblock regularization, Class label smoothing</p>
<p>BoS for backbone: Mish activation, Cross-stage partial connections(CSP), Multi-input weighted residual connections</p>
<p>BoF for detector: CIoU-loss, CmBN, DropBlock regularization, Mosaic data augmentation, Self-Adversarial Training, Eliminate grid sensitivity, Using multiple anchors for a single ground truth, Cosine annealing scheduler, Optimal hyper-parameters, Random training shapes</p>
<p>BoS for detector: Mish activation, SPP-block, SAM-block, PAN path-aggregation block, DIoU-NMS</p>
</li>
</ul>
</li>
<li><p>Experiments</p>
<ul>
<li>Experimental setup</li>
<li>Influence of different features on Classifier training</li>
<li>Influence of different features on Detector training</li>
<li>Influence of different backbones and pre-trained weightings on Detector training</li>
<li>Influence of different mini-batch size on Detector training</li>
</ul>
</li>
<li><p>Results</p>
</li>
<li><p>Conclusions</p>
</li>
<li><p>Acknowledgements</p>
</li>
</ol>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">rgwang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://rgwang.github.io/2020/09/01/yolo4_paper/">https://rgwang.github.io/2020/09/01/yolo4_paper/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://rgwang.github.io" target="_blank">rgwang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/object-detection/">object detection</a><a class="post-meta__tags" href="/tags/YOLOv4/">YOLOv4</a></div><div class="post_share"><div class="social-share" data-image="/img/ball-ball-shaped-color-earth-269724.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/08/17/deepshare_python%E5%9F%BA%E7%A1%8015/"><img class="next_cover" src="/img/aerial-photography-of-green-forest-695299.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">python基础15(时间复杂度)</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/07/13/YOLOv1(You-Only-Look-Once)/" title="YOLOv1(You Only Look Once)"><img class="relatedPosts_cover" src="/img/ball-ball-shaped-color-earth-269724.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-13</div><div class="relatedPosts_title">YOLOv1(You Only Look Once)</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/09/目标检测mAP(mean Average Precision)/" title="目标检测mAP(mean Average Precision)"><img class="relatedPosts_cover" src="/img/abstract-blackboard-bulb-chalk-355948.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-09</div><div class="relatedPosts_title">目标检测mAP(mean Average Precision)</div></div></a></div></div><div class="clear_both"></div></div></article></main><footer id="footer" style="background-image: url(/img/ball-ball-shaped-color-earth-269724.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By rgwang</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi,welcome to my blog!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/js/third-party/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="/js/search/local-search.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>