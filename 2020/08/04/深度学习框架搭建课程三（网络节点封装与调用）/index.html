<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>深度学习框架搭建课程三（网络节点封装与调用） | rgwang</title><meta name="description" content="defaultdict用法 普通的字典时，用法一般是dict&#x3D;{},添加元素的只需要dict[element] &#x3D;value即，调用的时候也是如此，dict[element] &#x3D; xxx,但前提是element在字典里，如果不在字典里就会报错。 defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。 defaultdict接受一个工厂函数作"><meta name="keywords" content="DL,framework"><meta name="author" content="rgwang"><meta name="copyright" content="rgwang"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="深度学习框架搭建课程三（网络节点封装与调用）"><meta name="twitter:description" content="defaultdict用法 普通的字典时，用法一般是dict&#x3D;{},添加元素的只需要dict[element] &#x3D;value即，调用的时候也是如此，dict[element] &#x3D; xxx,但前提是element在字典里，如果不在字典里就会报错。 defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。 defaultdict接受一个工厂函数作"><meta name="twitter:image" content="https://rgwang.github.io/img/abstract-blackboard-bulb-chalk-355948.jpg"><meta property="og:type" content="article"><meta property="og:title" content="深度学习框架搭建课程三（网络节点封装与调用）"><meta property="og:url" content="https://rgwang.github.io/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/"><meta property="og:site_name" content="rgwang"><meta property="og:description" content="defaultdict用法 普通的字典时，用法一般是dict&#x3D;{},添加元素的只需要dict[element] &#x3D;value即，调用的时候也是如此，dict[element] &#x3D; xxx,但前提是element在字典里，如果不在字典里就会报错。 defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。 defaultdict接受一个工厂函数作"><meta property="og:image" content="https://rgwang.github.io/img/abstract-blackboard-bulb-chalk-355948.jpg"><meta property="article:published_time" content="2020-08-04T12:23:24.920Z"><meta property="article:modified_time" content="2020-08-04T12:28:51.223Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://rgwang.github.io/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/"><link rel="prev" title="deepshape_python基础2" href="https://rgwang.github.io/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%802/"><link rel="next" title="深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）" href="https://rgwang.github.io/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%BA%8C%EF%BC%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%EF%BC%89/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://rgwang.github.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/1971a47ac42c3aad3425f91b89c64fd4.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#defaultdict用法"><span class="toc-number">1.</span> <span class="toc-text">defaultdict用法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#isinstance-object-classinfo"><span class="toc-number">2.</span> <span class="toc-text">isinstance(object, classinfo)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#对前面建立的模型前向和反向传播过程可视化"><span class="toc-number">3.</span> <span class="toc-text">对前面建立的模型前向和反向传播过程可视化</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/abstract-blackboard-bulb-chalk-355948.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">rgwang</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">深度学习框架搭建课程三（网络节点封装与调用）</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-08-04 20:23:24"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-08-04</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-08-04 20:28:51"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-08-04</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Deep-Learning/">Deep Learning</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 9 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="defaultdict用法"><a href="#defaultdict用法" class="headerlink" title="defaultdict用法"></a>defaultdict用法</h2><ul>
<li><strong>普通的字典时，用法一般是dict={},添加元素的只需要dict[element] =value即，调用的时候也是如此，dict[element] = xxx,但前提是element在字典里，如果不在字典里就会报错。</strong></li>
<li><strong>defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。</strong><ul>
<li><strong>defaultdict接受一个工厂函数作为参数，如下来构造：</strong></li>
<li><strong>dict =defaultdict( factory_function)</strong></li>
<li><strong>factory_function可以是list、set、str等等，作用是当key不存在时，返回的是工厂函数的默认值，比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0</strong></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 节点类中，forward方法用于计算前向传播过程中每个节点的值value，backward方法用于计算反向传播过程中每个节点的输入相对于网络loss的偏导</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span> <span class="comment"># 节点基类</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inputs=[], name=None, is_trainable=True)</span>:</span> <span class="comment"># inputs为当前Node的输入节点</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        self.outputs = []</span><br><span class="line">        self.name = name</span><br><span class="line">        self.value = <span class="literal">None</span></span><br><span class="line">        self.is_trainable = is_trainable</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> input_ <span class="keyword">in</span> self.inputs: <span class="comment"># 当前节点的输入也是节点类，</span></span><br><span class="line">                                   <span class="comment"># 这里把当前节点写入其输入节点的输出属性</span></span><br><span class="line">            input_.outputs.append(self)</span><br><span class="line">            </span><br><span class="line">        self.gradients = defaultdict(int)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError <span class="comment"># python标准异常之一:尚未处理的方法</span></span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span> <span class="comment"># __repr__() 方法是类的实例化对象用来做</span></span><br><span class="line">                        <span class="comment">#“自我介绍”的方法，默认情况下，它会返</span></span><br><span class="line">                        <span class="comment">#回当前对象的“类名+object at+内存地址”，</span></span><br><span class="line">                        <span class="comment">#而如果对该方法进行重写，可以为其制作自定</span></span><br><span class="line">                        <span class="comment">#义的自我描述信息</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Placeholder</span><span class="params">(Node)</span>:</span> </span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    该节点（占位符）用来作为图的输入，当运行forward函数时，对其赋值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, is_trainable=True)</span>:</span></span><br><span class="line">        Node.__init__(self, name=name, is_trainable=is_trainable)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, value=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: self.value = value</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            self.gradients[self] = n.gradients[self] * <span class="number">1</span>  </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Linear</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x=None, weight=None, bias=None, name=None, is_trainable=False)</span>:</span> <span class="comment"># w * x + b</span></span><br><span class="line">        Node.__init__(self, [x, weight, bias], name=name)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        k, x, b = self.inputs[<span class="number">1</span>], self.inputs[<span class="number">0</span>], self.inputs[<span class="number">2</span>]</span><br><span class="line">        </span><br><span class="line">        self.value = k.value * x.value + b.value</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        k, x, b = self.inputs[<span class="number">1</span>], self.inputs[<span class="number">0</span>], self.inputs[<span class="number">2</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self] </span><br><span class="line">            </span><br><span class="line">            self.gradients[k] = grad_cost * x.value</span><br><span class="line">            self.gradients[b] = grad_cost * <span class="number">1</span></span><br><span class="line">            self.gradients[x] = grad_cost * k.value</span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sigmoid</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [x], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.x = self.inputs[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_sigmoid</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1</span> + np.exp(<span class="number">-1</span> * x))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.value = self._sigmoid(self.x.value)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._sigmoid(self.x.value) * (<span class="number">1</span> - self._sigmoid(self.x.value))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            self.gradients[self.x] = grad_cost * self.partial()             </span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Relu</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [x], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.x = x</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.value = self.x.value * (self.x.value &gt; <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> self.outputs:</span><br><span class="line">            grad_cost = n.gradients[self]</span><br><span class="line">            self.gradients[self.x] = grad_cost * (self.x.value &gt; <span class="number">0</span>) </span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">L2_Loss</span><span class="params">(Node)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, y, y_hat, name=None, is_trainable=False)</span>:</span></span><br><span class="line">        Node.__init__(self, [y, y_hat], name=name, is_trainable=is_trainable)</span><br><span class="line">        self.y = y</span><br><span class="line">        self.y_hat = y_hat</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self)</span>:</span>        </span><br><span class="line">        y_v = np.array(self.y.value)</span><br><span class="line">        yhat_v = np.array(self.y_hat.value)</span><br><span class="line">        self.value = np.mean((y_v - yhat_v) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 1/n sum (y- yhat)**2</span></span><br><span class="line">        y_v = np.array(self.y.value)</span><br><span class="line">        yhat_v = np.array(self.y_hat.value)</span><br><span class="line">        self.gradients[self.y] = <span class="number">2</span> * np.mean((y_v - yhat_v))</span><br><span class="line">        self.gradients[self.y_hat] = <span class="number">-2</span> * np.mean((y_v - yhat_v))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toplogic</span><span class="params">(graph)</span>:</span> <span class="comment"># 用于对人为设置的计算图排序，返回传播过程的节点顺序列表</span></span><br><span class="line">    sorted_node = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> len(graph) &gt; <span class="number">0</span>:</span><br><span class="line">        all_inputs = []</span><br><span class="line">        all_outputs = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> graph:</span><br><span class="line">            all_inputs += graph[n] <span class="comment"># 收集所有有输入的节点</span></span><br><span class="line">            all_outputs.append(n) <span class="comment"># 收集所有有输出的节点</span></span><br><span class="line">            </span><br><span class="line">        all_inputs = set(all_inputs)</span><br><span class="line">        all_outputs = set(all_outputs)</span><br><span class="line"></span><br><span class="line">        need_remove = all_outputs - all_inputs <span class="comment"># 有输出的节点集合</span></span><br><span class="line">                                               <span class="comment"># -有输入的节点集合</span></span><br><span class="line">                                               <span class="comment"># =只有输出，没有输</span></span><br><span class="line">                                               <span class="comment"># 入的节点集合</span></span><br><span class="line">        <span class="comment">#print(need_remove)</span></span><br><span class="line">        <span class="keyword">if</span> len(need_remove) &gt; <span class="number">0</span>:</span><br><span class="line">            node = random.choice(list(need_remove))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> len(graph) == <span class="number">1</span>: temp = graph[node]</span><br><span class="line">            graph.pop(node) <span class="comment"># 删除该节点</span></span><br><span class="line">            sorted_node.append(node)</span><br><span class="line">            <span class="keyword">if</span> len(graph) &lt; <span class="number">1</span>: sorted_node += temp</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> sorted_node</span><br></pre></td></tr></table></figure>
<h2 id="isinstance-object-classinfo"><a href="#isinstance-object-classinfo" class="headerlink" title="isinstance(object, classinfo)"></a>isinstance(object, classinfo)</h2><ul>
<li>isinstance() 函数来判断一个对象是否是一个已知的类型，类似 type()</li>
<li>isinstance() 与 type() 区别：<ul>
<li>type() 不会认为子类是一种父类类型，不考虑继承关系。</li>
<li>isinstance() 会认为子类是一种父类类型，考虑继承关系。</li>
<li>如果要判断两个类型是否相同推荐使用 isinstance()</li>
</ul>
</li>
<li>object — 实例对象</li>
<li>classinfo — 可以是直接或间接类名、基本类型或者由它们组成的元组</li>
<li>如果对象的类型与参数二的类型（classinfo）相同则返回 True，否则返回 False</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_feed_dict_to_graph</span><span class="params">(feed_dict)</span>:</span> <span class="comment"># feed_dict是整个网络初始化时的输入节点字典，其中key为输入节点，value为对应的输入值</span></span><br><span class="line">    computing_graph = defaultdict(list)</span><br><span class="line">    </span><br><span class="line">    nodes = [n <span class="keyword">for</span> n <span class="keyword">in</span> feed_dict] <span class="comment"># 从feed_dict中取出key值构成节点列表</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> nodes:</span><br><span class="line">        n = nodes.pop(<span class="number">0</span>) <span class="comment"># 返回并删除nodes列表中的第一个元素</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> isinstance(n, Placeholder): <span class="comment"># 判断该元素是否是Placeholder类，Placeholder类为输入节点类，</span></span><br><span class="line">                                       <span class="comment"># 若为Placeholder类，则将feed_dict中对应的value赋给该元素。</span></span><br><span class="line">            n.value = feed_dict[n]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> n <span class="keyword">in</span> computing_graph: <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> n.outputs: <span class="comment"># 对该元素的输出使用for循环，将其输出添加至computing_graph字典中对应该元素的value列表中，</span></span><br><span class="line">                            <span class="comment"># 表示该键值对满足一对输入输出节点关系。</span></span><br><span class="line">            computing_graph[n].append(m)</span><br><span class="line">            nodes.append(m)</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> computing_graph <span class="comment"># 返回的computing_graph即为人为设置的网络结构计算图</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topological_sort_feed_dict</span><span class="params">(feed_dict)</span>:</span> <span class="comment"># 拓扑排序，返回网络传播过程各节点的排列顺序列表</span></span><br><span class="line">    graph = convert_feed_dict_to_graph(feed_dict)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> toplogic(graph)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_and_backward</span><span class="params">(graph_order, monitor=False)</span>:</span> <span class="comment"># 对graph_order列表中的节点依次进行前向和反向传播，更新每个节点的值和梯度</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph_order:</span><br><span class="line">        <span class="keyword">if</span> monitor:</span><br><span class="line">            print(<span class="string">'forward computing -- &#123;&#125;'</span>.format(node))</span><br><span class="line">        node.forward()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> node <span class="keyword">in</span> graph_order[::<span class="number">-1</span>]:</span><br><span class="line">        <span class="keyword">if</span> monitor:</span><br><span class="line">            print(<span class="string">'backward computing -- &#123;&#125;'</span>.format(node))</span><br><span class="line">        node.backward()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(graph, learning_rate=<span class="number">1e-2</span>)</span>:</span> <span class="comment"># 权重优化函数，对is_trainable==True的节点进行负梯度方向的优化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> t.is_trainable:</span><br><span class="line">            t.value += <span class="number">-1</span> * learning_rate * t.gradients[t]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">data = load_boston()</span><br><span class="line">X_, y_ = data[<span class="string">'data'</span>], data[<span class="string">'target'</span>] <span class="comment"># 分别赋值</span></span><br><span class="line">X_rm = X_[:,<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别给各权重设定初始值</span></span><br><span class="line">w1_, b1_ = np.random.normal(), np.random.normal() </span><br><span class="line">w2_, b2_ = np.random.normal(), np.random.normal()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义所有Placeholder类的输入节点</span></span><br><span class="line">X, y = Placeholder(name=<span class="string">'X'</span>, is_trainable=<span class="literal">False</span>), Placeholder(name=<span class="string">'y'</span>, is_trainable=<span class="literal">False</span>)</span><br><span class="line">w1, b1 = Placeholder(name=<span class="string">'w1'</span>), Placeholder(name=<span class="string">'b1'</span>)</span><br><span class="line">w2, b2 = Placeholder(name=<span class="string">'w2'</span>), Placeholder(name=<span class="string">'b2'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型，根据前面各种节点类方法的定义，以下声明实例的方法会自动设置好各个节点间的输入输出关系</span></span><br><span class="line">output1 = Linear(X, w1, b1, name=<span class="string">'Linear-01'</span>,)</span><br><span class="line">output2 = Sigmoid(output1, name=<span class="string">'activation'</span>)</span><br><span class="line">y_hat = Linear(output2, w2, b2, name=<span class="string">'y_hat'</span>)</span><br><span class="line">cost = L2_Loss(y, y_hat, name=<span class="string">'cost'</span>)</span><br><span class="line"></span><br><span class="line">feed_dict = &#123; <span class="comment"># 建立输入节点和其初始值的对应关系</span></span><br><span class="line">    X: X_rm,</span><br><span class="line">    y: y_,</span><br><span class="line">    w1: w1_,</span><br><span class="line">    w2: w2_,</span><br><span class="line">    b1: b1_,</span><br><span class="line">    b2: b2_,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">graph_sort = topological_sort_feed_dict(feed_dict)</span><br><span class="line"></span><br><span class="line">epoch = <span class="number">1000</span></span><br><span class="line">batch_num = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line">losses = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> tqdm(range(epoch)):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> range(batch_num): <span class="comment"># 每次随机对一个点的loss进行优化</span></span><br><span class="line">        index = np.random.choice(range(len(X_rm)))</span><br><span class="line">        X.value = X_rm[index]</span><br><span class="line">        y.value = y_[index]</span><br><span class="line">        </span><br><span class="line">        forward_and_backward(graph_sort, monitor=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        optimize(graph_sort, learning_rate)</span><br><span class="line">        </span><br><span class="line">        loss += cost.value</span><br><span class="line">    <span class="comment">#print(loss)</span></span><br><span class="line">    losses.append(loss / batch_num)</span><br></pre></td></tr></table></figure>
<pre><code>HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value=&#39;&#39;)))
</code></pre><p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(x, graph)</span>:</span> <span class="comment"># 用训练结束后的模型推理</span></span><br><span class="line">    X.value = x</span><br><span class="line">    forward_and_backward(graph)</span><br><span class="line">    <span class="keyword">return</span> y_hat.value</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(losses)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fdde0fe6090&gt;]
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/2e7788273e841246ed82ebc384201c0e.png" alt="output_14_1"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(X_rm, y_)</span><br><span class="line">plot_x = np.linspace(min(X_rm), max(X_rm), <span class="number">1000</span>)</span><br><span class="line">plt.scatter(plot_x, [predict(x, graph_sort) <span class="keyword">for</span> x <span class="keyword">in</span> plot_x], s=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7fdde0a65690&gt;
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/464d16ea17f3526e25f38e70cac37000.png" alt="output_15_1"></p>
<h2 id="对前面建立的模型前向和反向传播过程可视化"><a href="#对前面建立的模型前向和反向传播过程可视化" class="headerlink" title="对前面建立的模型前向和反向传播过程可视化"></a>对前面建立的模型前向和反向传播过程可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">computing_graph = convert_feed_dict_to_graph(feed_dict)</span><br><span class="line">graph = nx.DiGraph(computing_graph)</span><br><span class="line">layout = nx.layout.spring_layout(graph)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visited_procedure</span><span class="params">(graph, position, visited_order, step, sub_plot_index=None, colors=<span class="params">(<span class="string">'red'</span>, <span class="string">'green'</span>)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 将图graph按照访问顺序visited_order变换颜色</span></span><br><span class="line">    changed = visited_order[:step] <span class="keyword">if</span> step <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> visited_order</span><br><span class="line">    </span><br><span class="line">    before, after = colors</span><br><span class="line">    </span><br><span class="line">    color_map = [after <span class="keyword">if</span> c <span class="keyword">in</span> changed <span class="keyword">else</span> before <span class="keyword">for</span> c <span class="keyword">in</span> graph]</span><br><span class="line">    </span><br><span class="line">    nx.draw(graph, position, node_color=color_map, with_labels=<span class="literal">True</span>,ax=sub_plot_index)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(graph_sort)**<span class="number">0.5</span>)</span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(graph_sort)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, graph_sort, step=i, sub_plot_index=ax[ix])</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/7f8637596110340f2a255a77744622b8.png" alt="output_20_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dimension = int(len(graph_sort)**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(dimension, dimension+<span class="number">1</span>,figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(graph_sort)+<span class="number">1</span>):</span><br><span class="line">    ix = np.unravel_index(i, ax.shape) <span class="comment"># 返回索引i在形为ax.shape的数组里的位置</span></span><br><span class="line">    plt.sca(ax[ix]) <span class="comment"># plt.sca(ax[index])选择显示哪个图</span></span><br><span class="line">    ax[ix].title.set_text(<span class="string">'Forward Propagation Step:&#123;&#125;'</span>.format(i))</span><br><span class="line">    visited_procedure(graph, layout, graph_sort[::<span class="number">-1</span>], step=i, sub_plot_index=ax[ix], colors=(<span class="string">'green'</span>,<span class="string">'red'</span>))</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/rgwang/CDN@latest/2020/08/04/aa59a48142b4f97c246628520f383729.png" alt="output_21_0"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">rgwang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://rgwang.github.io/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/">https://rgwang.github.io/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%B8%89%EF%BC%88%E7%BD%91%E7%BB%9C%E8%8A%82%E7%82%B9%E5%B0%81%E8%A3%85%E4%B8%8E%E8%B0%83%E7%94%A8%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://rgwang.github.io" target="_blank">rgwang</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DL/">DL</a><a class="post-meta__tags" href="/tags/framework/">framework</a></div><div class="post_share"><div class="social-share" data-image="/img/volcano-erupting-at-night-under-starry-sky-4220967.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/06/deepshare_python%E5%9F%BA%E7%A1%802/"><img class="prev_cover" src="/img/landscape-photo-of-mountain-with-polar-lights-1434608.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">deepshape_python基础2</div></div></a></div><div class="next-post pull_right"><a href="/2020/08/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E8%AF%BE%E7%A8%8B%E4%BA%8C%EF%BC%88%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E3%80%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%EF%BC%89/"><img class="next_cover" src="/img/volcano-erupting-at-night-under-starry-sky-4220967.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/03/深度学习框架搭建课程一（线性回归与梯度下降）/" title="深度学习框架搭建课程一（线性回归与梯度下降）"><img class="relatedPosts_cover" src="/img/ball-ball-shaped-color-earth-269724.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-03</div><div class="relatedPosts_title">深度学习框架搭建课程一（线性回归与梯度下降）</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/04/深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）/" title="深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）"><img class="relatedPosts_cover" src="/img/volcano-erupting-at-night-under-starry-sky-4220967.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-08-04</div><div class="relatedPosts_title">深度学习框架搭建课程二（反向传播、激活函数、拓扑排序）</div></div></a></div></div><div class="clear_both"></div></div></article></main><footer id="footer" style="background-image: url(/img/abstract-blackboard-bulb-chalk-355948.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By rgwang</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi,welcome to my blog!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/js/third-party/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="/js/search/local-search.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>